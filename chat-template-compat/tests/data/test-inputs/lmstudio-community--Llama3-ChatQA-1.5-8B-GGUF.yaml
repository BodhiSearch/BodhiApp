id: lmstudio-community/Llama3-ChatQA-1.5-8B-GGUF
base: nvidia/Llama3-ChatQA-1.5-8B
variables:
  - add_generation_prompt
  - bos_token
  - messages
bos_token: <|begin_of_text|>
template: |-
  {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>

  '+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>

  ' }}{% endif %}
