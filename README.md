# BodhiServer

Run LLMs locally.

BodhiServer runs LLMs and other GenerativeAI inference locally. It also exposes these features as authenticated services.

This allows GenAI based native applications, chrome extensions, or web pages use the local user's GPU/CPU to run inference and provide GenAI features without any paid API calls.
