// This file is auto-generated by @hey-api/openapi-ts

/**
 * Flat enum representing all types of model aliases
 * Each variant is identified by the source field
 */
export type Alias = (UserAlias & {
    source: 'user';
}) | (ModelAlias & {
    source: 'model';
}) | (ApiAlias & {
    source: 'api';
});

export type ApiAlias = {
    id: string;
    api_format: ApiFormat;
    base_url: string;
    models: Array<string>;
    prefix?: string | null;
    created_at: string;
    updated_at: string;
};

/**
 * API format/protocol specification
 */
export type ApiFormat = 'openai' | 'placeholder';

/**
 * Response containing available API formats
 */
export type ApiFormatsResponse = {
    data: Array<ApiFormat>;
};

/**
 * Validated API key wrapper - validates length when Some, allows None for public APIs
 */
export type ApiKey = string | null;

/**
 * Represents an API key update action for API model updates
 */
export type ApiKeyUpdateAction = {
    action: 'keep';
} | {
    /**
     * Set a new API key (or add one if none exists) - can be None for public APIs
     */
    value: ApiKey;
    action: 'set';
};

/**
 * Response containing API model configuration
 */
export type ApiModelResponse = {
    id: string;
    api_format: ApiFormat;
    base_url: string;
    api_key_masked?: string | null;
    models: Array<string>;
    prefix?: string | null;
    created_at: string;
    updated_at: string;
};

export type ApiToken = {
    id: string;
    user_id: string;
    name: string;
    token_prefix: string;
    token_hash: string;
    scopes: string;
    status: TokenStatus;
    created_at: string;
    updated_at: string;
};

export type ApiTokenResponse = {
    /**
     * API token with bodhiapp_ prefix for programmatic access
     */
    token: string;
};

export type AppAccessRequest = {
    app_client_id: string;
};

export type AppAccessResponse = {
    scope: string;
};

/**
 * Application information and status
 */
export type AppInfo = {
    /**
     * Application version number (semantic versioning)
     */
    version: string;
    /**
     * Git commit SHA of the build
     */
    commit_sha: string;
    /**
     * Current application setup and operational status
     */
    status: AppStatus;
};

export type AppRole = ResourceRole | TokenScope | UserScope;

export type AppStatus = 'setup' | 'ready' | 'resource-admin';

/**
 * Request body for approving access with role assignment
 */
export type ApproveUserAccessRequest = {
    /**
     * Role to assign to the user
     */
    role: ResourceRole;
};

export type AuthCallbackRequest = {
    /**
     * OAuth authorization code from successful authentication (required for success flow)
     */
    code?: string | null;
    /**
     * OAuth state parameter for CSRF protection (must match initiated request)
     */
    state?: string | null;
    /**
     * OAuth error code if authentication failed (e.g., "access_denied")
     */
    error?: string | null;
    /**
     * Human-readable OAuth error description if authentication failed
     */
    error_description?: string | null;
    [key: string]: string | (string | null) | (string | null) | (string | null) | (string | null) | undefined;
};

/**
 * Change user role request
 */
export type ChangeRoleRequest = {
    /**
     * Role to assign to the user
     */
    role: string;
};

export type ChatChoice = {
    /**
     * The index of the choice in the list of choices.
     */
    index: number;
    message: ChatCompletionResponseMessage;
    finish_reason?: null | FinishReason;
    logprobs?: null | ChatChoiceLogprobs;
};

export type ChatChoiceLogprobs = {
    /**
     * A list of message content tokens with log probability information.
     */
    content?: Array<ChatCompletionTokenLogprob> | null;
    refusal?: Array<ChatCompletionTokenLogprob> | null;
};

export type ChatChoiceStream = {
    /**
     * The index of the choice in the list of choices.
     */
    index: number;
    delta: ChatCompletionStreamResponseDelta;
    finish_reason?: null | FinishReason;
    logprobs?: null | ChatChoiceLogprobs;
};

export type ChatCompletionAudio = {
    /**
     * The voice the model uses to respond. Supported voices are `ash`, `ballad`, `coral`, `sage`, and `verse` (also supported but not recommended are `alloy`, `echo`, and `shimmer`; these voices are less expressive).
     */
    voice: ChatCompletionAudioVoice;
    /**
     * Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`, `opus`, or `pcm16`.
     */
    format: ChatCompletionAudioFormat;
};

export type ChatCompletionAudioFormat = 'wav' | 'mp3' | 'flac' | 'opus' | 'pcm16';

export type ChatCompletionAudioVoice = 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';

export type ChatCompletionFunctionCall = 'none' | 'auto' | {
    /**
     * Forces the model to call the specified function.
     */
    Function: {
        name: string;
    };
};

/**
 * @deprecated
 */
export type ChatCompletionFunctions = {
    /**
     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: string;
    /**
     * A description of what the function does, used by the model to choose when and how to call the function.
     */
    description?: string | null;
    /**
     * The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
     *
     * Omitting `parameters` defines a function with an empty parameter list.
     */
    parameters: unknown;
};

export type ChatCompletionMessageToolCall = {
    /**
     * The ID of the tool call.
     */
    id: string;
    /**
     * The type of the tool. Currently, only `function` is supported.
     */
    type: ChatCompletionToolType;
    /**
     * The function that the model called.
     */
    function: FunctionCall;
};

export type ChatCompletionMessageToolCallChunk = {
    index: number;
    /**
     * The ID of the tool call.
     */
    id?: string | null;
    type?: null | ChatCompletionToolType;
    function?: null | FunctionCallStream;
};

/**
 * Output types that you would like the model to generate for this request.
 *
 * Most models are capable of generating text, which is the default: `["text"]`
 *
 * The `gpt-4o-audio-preview` model can also be used to [generate
 * audio](https://platform.openai.com/docs/guides/audio). To request that this model generate both text and audio responses, you can use: `["text", "audio"]`
 */
export type ChatCompletionModalities = 'text' | 'audio';

/**
 * Specifies a tool the model should use. Use to force the model to call a specific function.
 */
export type ChatCompletionNamedToolChoice = {
    /**
     * The type of the tool. Currently, only `function` is supported.
     */
    type: ChatCompletionToolType;
    function: FunctionName;
};

export type ChatCompletionRequestAssistantMessage = {
    content?: null | ChatCompletionRequestAssistantMessageContent;
    /**
     * The refusal message by the assistant.
     */
    refusal?: string | null;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
    audio?: null | ChatCompletionRequestAssistantMessageAudio;
    tool_calls?: Array<ChatCompletionMessageToolCall> | null;
    function_call?: null | FunctionCall;
};

export type ChatCompletionRequestAssistantMessageAudio = {
    /**
     * Unique identifier for a previous audio response from the model.
     */
    id: string;
};

export type ChatCompletionRequestAssistantMessageContent = string | Array<ChatCompletionRequestAssistantMessageContentPart>;

export type ChatCompletionRequestAssistantMessageContentPart = (ChatCompletionRequestMessageContentPartText & {
    type: 'text';
}) | (ChatCompletionRequestMessageContentPartRefusal & {
    type: 'refusal';
});

export type ChatCompletionRequestDeveloperMessage = {
    /**
     * The contents of the developer message.
     */
    content: ChatCompletionRequestDeveloperMessageContent;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
};

export type ChatCompletionRequestDeveloperMessageContent = string | Array<ChatCompletionRequestMessageContentPartText>;

export type ChatCompletionRequestFunctionMessage = {
    /**
     * The return value from the function call, to return to the model.
     */
    content?: string | null;
    /**
     * The name of the function to call.
     */
    name: string;
};

export type ChatCompletionRequestMessage = (ChatCompletionRequestDeveloperMessage & {
    role: 'developer';
}) | (ChatCompletionRequestSystemMessage & {
    role: 'system';
}) | (ChatCompletionRequestUserMessage & {
    role: 'user';
}) | (ChatCompletionRequestAssistantMessage & {
    role: 'assistant';
}) | (ChatCompletionRequestToolMessage & {
    role: 'tool';
}) | (ChatCompletionRequestFunctionMessage & {
    role: 'function';
});

/**
 * Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).
 */
export type ChatCompletionRequestMessageContentPartAudio = {
    input_audio: InputAudio;
};

export type ChatCompletionRequestMessageContentPartImage = {
    image_url: ImageUrl;
};

export type ChatCompletionRequestMessageContentPartRefusal = {
    /**
     * The refusal message generated by the model.
     */
    refusal: string;
};

export type ChatCompletionRequestMessageContentPartText = {
    text: string;
};

export type ChatCompletionRequestSystemMessage = {
    /**
     * The contents of the system message.
     */
    content: ChatCompletionRequestSystemMessageContent;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
};

export type ChatCompletionRequestSystemMessageContent = string | Array<ChatCompletionRequestSystemMessageContentPart>;

export type ChatCompletionRequestSystemMessageContentPart = ChatCompletionRequestMessageContentPartText & {
    type: 'text';
};

/**
 * Tool message
 */
export type ChatCompletionRequestToolMessage = {
    /**
     * The contents of the tool message.
     */
    content: ChatCompletionRequestToolMessageContent;
    tool_call_id: string;
};

export type ChatCompletionRequestToolMessageContent = string | Array<ChatCompletionRequestToolMessageContentPart>;

export type ChatCompletionRequestToolMessageContentPart = ChatCompletionRequestMessageContentPartText & {
    type: 'text';
};

export type ChatCompletionRequestUserMessage = {
    /**
     * The contents of the user message.
     */
    content: ChatCompletionRequestUserMessageContent;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
};

export type ChatCompletionRequestUserMessageContent = string | Array<ChatCompletionRequestUserMessageContentPart>;

export type ChatCompletionRequestUserMessageContentPart = (ChatCompletionRequestMessageContentPartText & {
    type: 'text';
}) | (ChatCompletionRequestMessageContentPartImage & {
    type: 'image_url';
}) | (ChatCompletionRequestMessageContentPartAudio & {
    type: 'input_audio';
});

/**
 * A chat completion message generated by the model.
 */
export type ChatCompletionResponseMessage = {
    /**
     * The contents of the message.
     */
    content?: string | null;
    /**
     * The refusal message generated by the model.
     */
    refusal?: string | null;
    /**
     * The tool calls generated by the model, such as function calls.
     */
    tool_calls?: Array<ChatCompletionMessageToolCall> | null;
    /**
     * The role of the author of this message.
     */
    role: Role;
    function_call?: null | FunctionCall;
    audio?: null | ChatCompletionResponseMessageAudio;
};

export type ChatCompletionResponseMessageAudio = {
    /**
     * Unique identifier for this audio response.
     */
    id: string;
    /**
     * The Unix timestamp (in seconds) for when this audio response will no longer be accessible on the server for use in multi-turn conversations.
     */
    expires_at: number;
    /**
     * Base64 encoded audio bytes generated by the model, in the format specified in the request.
     */
    data: string;
    /**
     * Transcript of the audio generated by the model.
     */
    transcript: string;
};

/**
 * Options for streaming response. Only set this when you set `stream: true`.
 */
export type ChatCompletionStreamOptions = {
    /**
     * If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value.
     */
    include_usage: boolean;
};

/**
 * A chat completion delta generated by streamed model responses.
 */
export type ChatCompletionStreamResponseDelta = {
    /**
     * The contents of the chunk message.
     */
    content?: string | null;
    function_call?: null | FunctionCallStream;
    tool_calls?: Array<ChatCompletionMessageToolCallChunk> | null;
    role?: null | Role;
    /**
     * The refusal message generated by the model.
     */
    refusal?: string | null;
};

export type ChatCompletionTokenLogprob = {
    /**
     * The token.
     */
    token: string;
    /**
     * The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
     */
    logprob: number;
    /**
     * A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
     */
    bytes?: Array<number> | null;
    /**
     * List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
     */
    top_logprobs: Array<TopLogprobs>;
};

export type ChatCompletionTool = {
    type: ChatCompletionToolType;
    function: FunctionObject;
};

/**
 * Controls which (if any) tool is called by the model.
 * `none` means the model will not call any tool and instead generates a message.
 * `auto` means the model can pick between generating a message or calling one or more tools.
 * `required` means the model must call one or more tools.
 * Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
 *
 * `none` is the default when no tools are present. `auto` is the default if tools are present.
 */
export type ChatCompletionToolChoiceOption = 'none' | 'auto' | 'required' | {
    named: ChatCompletionNamedToolChoice;
};

export type ChatCompletionToolType = 'function';

export type ChatRequest = {
    model: string;
    messages: Array<Message>;
    stream?: boolean | null;
    format?: string | null;
    keep_alive?: null | Duration;
    options?: null | Options;
};

/**
 * Breakdown of tokens used in a completion.
 */
export type CompletionTokensDetails = {
    accepted_prediction_tokens?: number | null;
    /**
     * Audio input tokens generated by the model.
     */
    audio_tokens?: number | null;
    /**
     * Tokens generated by the model for reasoning.
     */
    reasoning_tokens?: number | null;
    /**
     *  When using Predicted Outputs, the number of tokens in the
     * prediction that did not appear in the completion. However, like
     * reasoning tokens, these tokens are still counted in the total
     * completion tokens for purposes of billing, output, and context
     * window limits.
     */
    rejected_prediction_tokens?: number | null;
};

/**
 * Usage statistics for the completion request.
 */
export type CompletionUsage = {
    /**
     * Number of tokens in the prompt.
     */
    prompt_tokens: number;
    /**
     * Number of tokens in the generated completion.
     */
    completion_tokens: number;
    /**
     * Total number of tokens used in the request (prompt + completion).
     */
    total_tokens: number;
    prompt_tokens_details?: null | PromptTokensDetails;
    completion_tokens_details?: null | CompletionTokensDetails;
};

export type CreateAliasRequest = {
    alias: string;
    repo: string;
    filename: string;
    snapshot?: string | null;
    request_params?: null | OaiRequestParams;
    context_params?: Array<string> | null;
};

/**
 * Request to create a new API model configuration
 */
export type CreateApiModelRequest = {
    /**
     * API format/protocol (e.g., "openai")
     */
    api_format: ApiFormat;
    /**
     * API base URL
     */
    base_url: string;
    /**
     * API key for authentication (null for public APIs)
     */
    api_key?: ApiKey;
    /**
     * List of available models
     */
    models: Array<string>;
    /**
     * Optional prefix for model namespacing (e.g., "azure/" for "azure/gpt-4", "openai:" for "openai:gpt-4")
     */
    prefix?: string | null;
};

/**
 * Request to create a new API token
 */
export type CreateApiTokenRequest = {
    /**
     * Descriptive name for the API token (minimum 3 characters)
     */
    name?: string | null;
    /**
     * Token scope defining access level
     */
    scope: TokenScope;
};

export type CreateChatCompletionRequest = {
    /**
     * A list of messages comprising the conversation so far. Depending on the [model](https://platform.openai.com/docs/models) you use, different message types (modalities) are supported, like [text](https://platform.openai.com/docs/guides/text-generation), [images](https://platform.openai.com/docs/guides/vision), and [audio](https://platform.openai.com/docs/guides/audio).
     */
    messages: Array<ChatCompletionRequestMessage>;
    /**
     * ID of the model to use.
     * See the [model endpoint compatibility](https://platform.openai.com/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.
     */
    model: string;
    /**
     * Whether or not to store the output of this chat completion request
     *
     * for use in our [model distillation](https://platform.openai.com/docs/guides/distillation) or [evals](https://platform.openai.com/docs/guides/evals) products.
     */
    store?: boolean | null;
    reasoning_effort?: null | ReasoningEffort;
    /**
     * Developer-defined tags and values used for filtering completions in the [dashboard](https://platform.openai.com/chat-completions).
     */
    metadata?: unknown;
    /**
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
     */
    frequency_penalty?: number | null;
    /**
     * Modify the likelihood of specified tokens appearing in the completion.
     *
     * Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100.
     * Mathematically, the bias is added to the logits generated by the model prior to sampling.
     * The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection;
     * values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
     */
    logit_bias?: {} | null;
    /**
     * Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.
     */
    logprobs?: boolean | null;
    /**
     * An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.
     */
    top_logprobs?: number | null;
    /**
     * The maximum number of [tokens](https://platform.openai.com/tokenizer) that can be generated in the chat completion.
     *
     * This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.
     * This value is now deprecated in favor of `max_completion_tokens`, and is
     * not compatible with [o1 series models](https://platform.openai.com/docs/guides/reasoning).
     * @deprecated
     */
    max_tokens?: number | null;
    /**
     * An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
     */
    max_completion_tokens?: number | null;
    /**
     * How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
     */
    n?: number | null;
    modalities?: Array<ChatCompletionModalities> | null;
    prediction?: null | PredictionContent;
    audio?: null | ChatCompletionAudio;
    /**
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
     */
    presence_penalty?: number | null;
    response_format?: null | ResponseFormat;
    /**
     *  This feature is in Beta.
     * If specified, our system will make a best effort to sample deterministically, such that repeated requests
     * with the same `seed` and parameters should return the same result.
     * Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
     */
    seed?: number | null;
    service_tier?: null | ServiceTier;
    stop?: null | Stop;
    /**
     * If set, partial message deltas will be sent, like in ChatGPT.
     * Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
     * as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
     */
    stream?: boolean | null;
    stream_options?: null | ChatCompletionStreamOptions;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random,
     * while lower values like 0.2 will make it more focused and deterministic.
     *
     * We generally recommend altering this or `top_p` but not both.
     */
    temperature?: number | null;
    /**
     * An alternative to sampling with temperature, called nucleus sampling,
     * where the model considers the results of the tokens with top_p probability mass.
     * So 0.1 means only the tokens comprising the top 10% probability mass are considered.
     *
     * We generally recommend altering this or `temperature` but not both.
     */
    top_p?: number | null;
    /**
     * A list of tools the model may call. Currently, only functions are supported as a tool.
     * Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
     */
    tools?: Array<ChatCompletionTool> | null;
    tool_choice?: null | ChatCompletionToolChoiceOption;
    /**
     * Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling) during tool use.
     */
    parallel_tool_calls?: boolean | null;
    /**
     * A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
     */
    user?: string | null;
    web_search_options?: null | WebSearchOptions;
    function_call?: null | ChatCompletionFunctionCall;
    /**
     * Deprecated in favor of `tools`.
     *
     * A list of functions the model may generate JSON inputs for.
     * @deprecated
     */
    functions?: Array<ChatCompletionFunctions> | null;
};

/**
 * Represents a chat completion response returned by model, based on the provided input.
 */
export type CreateChatCompletionResponse = {
    /**
     * A unique identifier for the chat completion.
     */
    id: string;
    /**
     * A list of chat completion choices. Can be more than one if `n` is greater than 1.
     */
    choices: Array<ChatChoice>;
    /**
     * The Unix timestamp (in seconds) of when the chat completion was created.
     */
    created: number;
    /**
     * The model used for the chat completion.
     */
    model: string;
    service_tier?: null | ServiceTierResponse;
    /**
     * This fingerprint represents the backend configuration that the model runs with.
     *
     * Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
     */
    system_fingerprint?: string | null;
    /**
     * The object type, which is always `chat.completion`.
     */
    object: string;
    usage?: null | CompletionUsage;
};

/**
 * Represents a streamed chunk of a chat completion response returned by model, based on the provided input.
 */
export type CreateChatCompletionStreamResponse = {
    /**
     * A unique identifier for the chat completion. Each chunk has the same ID.
     */
    id: string;
    /**
     * A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {"include_usage": true}`.
     */
    choices: Array<ChatChoiceStream>;
    /**
     * The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
     */
    created: number;
    /**
     * The model to generate the completion.
     */
    model: string;
    service_tier?: null | ServiceTierResponse;
    /**
     * This fingerprint represents the backend configuration that the model runs with.
     * Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
     */
    system_fingerprint?: string | null;
    /**
     * The object type, which is always `chat.completion.chunk`.
     */
    object: string;
    usage?: null | CompletionUsage;
};

export type CreateEmbeddingRequest = {
    /**
     * ID of the model to use. You can use the
     * [List models](https://platform.openai.com/docs/api-reference/models/list)
     * API to see all of your available models, or see our
     * [Model overview](https://platform.openai.com/docs/models/overview)
     * for descriptions of them.
     */
    model: string;
    /**
     * Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
     */
    input: EmbeddingInput;
    encoding_format?: null | EncodingFormat;
    /**
     * A unique identifier representing your end-user, which will help OpenAI
     * to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/usage-policies/end-user-ids).
     */
    user?: string | null;
    /**
     * The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
     */
    dimensions?: number | null;
};

export type CreateEmbeddingResponse = {
    object: string;
    /**
     * The name of the model used to generate the embedding.
     */
    model: string;
    /**
     * The list of embeddings generated by the model.
     */
    data: Array<Embedding>;
    /**
     * The usage information for the request.
     */
    usage: EmbeddingUsage;
};

export type DownloadRequest = {
    id: string;
    repo: string;
    filename: string;
    status: DownloadStatus;
    error?: string | null;
    created_at: string;
    updated_at: string;
    total_bytes?: number | null;
    downloaded_bytes?: number;
    started_at: string;
};

export type DownloadStatus = 'pending' | 'completed' | 'error';

export type Duration = string;

/**
 * Represents an embedding vector returned by embedding endpoint.
 */
export type Embedding = {
    /**
     * The index of the embedding in the list of embeddings.
     */
    index: number;
    /**
     * The object type, which is always "embedding".
     */
    object: string;
    /**
     * The embedding vector, which is a list of floats. The length of vector
     * depends on the model as listed in the [embedding guide](https://platform.openai.com/docs/guides/embeddings).
     */
    embedding: Array<number>;
};

export type EmbeddingInput = string | Array<string> | Array<number> | Array<Array<number>>;

export type EmbeddingUsage = {
    /**
     * The number of tokens used by the prompt.
     */
    prompt_tokens: number;
    /**
     * The total number of tokens used by the request.
     */
    total_tokens: number;
};

export type EncodingFormat = 'float' | 'base64';

export type ErrorBody = {
    /**
     * Human-readable error message describing what went wrong
     */
    message: string;
    /**
     * Error type categorizing the kind of error that occurred
     */
    type: string;
    /**
     * Specific error code for programmatic error handling
     */
    code?: string | null;
    /**
     * Parameter name that caused the error (for validation errors)
     */
    param?: string | null;
};

/**
 * Request to fetch available models from provider
 */
export type FetchModelsRequest = {
    /**
     * Credentials to use for fetching models
     */
    creds?: TestCreds;
    /**
     * API base URL (required - always needed to know where to fetch models from)
     */
    base_url: string;
};

/**
 * Response containing available models from provider
 */
export type FetchModelsResponse = {
    models: Array<string>;
};

export type FinishReason = 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';

/**
 * The name and arguments of a function that should be called, as generated by the model.
 */
export type FunctionCall = {
    /**
     * The name of the function to call.
     */
    name: string;
    /**
     * The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
     */
    arguments: string;
};

export type FunctionCallStream = {
    /**
     * The name of the function to call.
     */
    name?: string | null;
    /**
     * The arguments to call the function with, as generated by the model in JSON format.
     * Note that the model does not always generate valid JSON, and may hallucinate
     * parameters not defined by your function schema. Validate the arguments in your
     * code before calling your function.
     */
    arguments?: string | null;
};

export type FunctionName = {
    /**
     * The name of the function to call.
     */
    name: string;
};

export type FunctionObject = {
    /**
     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: string;
    /**
     * A description of what the function does, used by the model to choose when and how to call the function.
     */
    description?: string | null;
    /**
     * The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
     *
     * Omitting `parameters` defines a function with an empty parameter list.
     */
    parameters?: unknown;
    /**
     * Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).
     */
    strict?: boolean | null;
};

export type ImageDetail = 'auto' | 'low' | 'high';

export type ImageUrl = {
    /**
     * Either a URL of the image or the base64 encoded image data.
     */
    url: string;
    detail?: null | ImageDetail;
};

export type InputAudio = {
    /**
     * Base64 encoded audio data.
     */
    data: string;
    /**
     * The format of the encoded audio data. Currently supports "wav" and "mp3".
     */
    format: InputAudioFormat;
};

export type InputAudioFormat = 'wav' | 'mp3';

export type ListModelResponse = {
    object: string;
    data: Array<{
        /**
         * The model identifier, which can be referenced in the API endpoints.
         */
        id: string;
        /**
         * The object type, which is always "model".
         */
        object: string;
        /**
         * The Unix timestamp (in seconds) when the model was created.
         */
        created: number;
        /**
         * The organization that owns the model.
         */
        owned_by: string;
    }>;
};

/**
 * List users query parameters
 */
export type ListUsersParams = {
    page?: number | null;
    page_size?: number | null;
};

export type LocalModelResponse = {
    repo: string;
    filename: string;
    snapshot: string;
    size?: number | null;
    model_params: {};
};

export type Message = {
    role: string;
    content: string;
    images?: Array<string> | null;
};

export type Model = {
    model: string;
    modified_at: number;
    size: number;
    digest: string;
    details: ModelDetails;
};

export type ModelAlias = {
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
};

export type ModelDetails = {
    parent_model?: string | null;
    format: string;
    family: string;
    families?: Array<string> | null;
    parameter_size: string;
    quantization_level: string;
};

/**
 * Describes an OpenAI model offering that can be used with the API.
 */
export type ModelResponse = {
    /**
     * The model identifier, which can be referenced in the API endpoints.
     */
    id: string;
    /**
     * The object type, which is always "model".
     */
    object: string;
    /**
     * The Unix timestamp (in seconds) when the model was created.
     */
    created: number;
    /**
     * The organization that owns the model.
     */
    owned_by: string;
};

export type ModelsResponse = {
    models: Array<Model>;
};

/**
 * Request to pull a model file from HuggingFace
 */
export type NewDownloadRequest = {
    /**
     * HuggingFace repository name in format 'username/repository-name'
     */
    repo: string;
    /**
     * Model file name to download (typically .gguf format)
     */
    filename: string;
};

export type OaiRequestParams = {
    frequency_penalty?: number | null;
    max_tokens?: number | null;
    presence_penalty?: number | null;
    seed?: number | null;
    stop?: Array<string>;
    temperature?: number | null;
    top_p?: number | null;
    user?: string | null;
};

export type OllamaError = {
    error: string;
};

export type OpenAiApiError = {
    /**
     * Error details following OpenAI API error format
     */
    error: ErrorBody;
};

export type Options = {
    num_keep?: number | null;
    seed?: number | null;
    num_predict?: number | null;
    top_k?: number | null;
    top_p?: number | null;
    tfs_z?: number | null;
    typical_p?: number | null;
    repeat_last_n?: number | null;
    temperature?: number | null;
    repeat_penalty?: number | null;
    presence_penalty?: number | null;
    frequency_penalty?: number | null;
    mirostat?: number | null;
    mirostat_tau?: number | null;
    mirostat_eta?: number | null;
    penalize_newline?: boolean | null;
    stop?: Array<string> | null;
    numa?: boolean | null;
    num_ctx?: number | null;
    num_batch?: number | null;
    num_gpu?: number | null;
    main_gpu?: number | null;
    low_vram?: boolean | null;
    f16_kv?: boolean | null;
    logits_all?: boolean | null;
    vocab_only?: boolean | null;
    use_mmap?: boolean | null;
    use_mlock?: boolean | null;
    num_thread?: number | null;
};

export type PaginatedAliasResponse = {
    data: Array<Alias>;
    total: number;
    page: number;
    page_size: number;
};

/**
 * Paginated response for API model listings
 */
export type PaginatedApiModelResponse = {
    data: Array<ApiModelResponse>;
    total: number;
    page: number;
    page_size: number;
};

export type PaginatedApiTokenResponse = {
    data: Array<ApiToken>;
    total: number;
    page: number;
    page_size: number;
};

export type PaginatedDownloadResponse = {
    data: Array<DownloadRequest>;
    total: number;
    page: number;
    page_size: number;
};

export type PaginatedLocalModelResponse = {
    data: Array<LocalModelResponse>;
    total: number;
    page: number;
    page_size: number;
};

/**
 * Paginated response for access requests
 */
export type PaginatedUserAccessResponse = {
    /**
     * List of access requests
     */
    requests: Array<UserAccessRequest>;
    /**
     * Total number of requests
     */
    total: number;
    /**
     * Current page number
     */
    page: number;
    /**
     * Number of items per page
     */
    page_size: number;
};

export type PaginatedUserAliasResponse = {
    data: Array<UserAliasResponse>;
    total: number;
    page: number;
    page_size: number;
};

/**
 * Query parameters for pagination and sorting
 */
export type PaginationSortParams = {
    /**
     * Page number (1-based indexing)
     */
    page?: number;
    /**
     * Number of items to return per page (maximum 100)
     */
    page_size?: number;
    /**
     * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
     */
    sort?: string | null;
    /**
     * Sort order: 'asc' for ascending, 'desc' for descending
     */
    sort_order?: string;
};

/**
 * Response to the ping endpoint
 */
export type PingResponse = {
    /**
     * Simple ping response message
     */
    message: string;
};

/**
 * The type of the predicted content you want to provide. This type is
 * currently always `content`.
 */
export type PredictionContent = {
    /**
     * The type of the predicted content you want to provide. This type is
     * currently always `content`.
     */
    content: PredictionContentContent;
    type: 'content';
};

/**
 * The content that should be matched when generating a model response. If generated tokens would match this content, the entire model response can be returned much more quickly.
 */
export type PredictionContentContent = string | Array<ChatCompletionRequestMessageContentPartText>;

/**
 * Breakdown of tokens used in a completion.
 */
export type PromptTokensDetails = {
    /**
     * Audio input tokens present in the prompt.
     */
    audio_tokens?: number | null;
    /**
     * Cached tokens present in the prompt.
     */
    cached_tokens?: number | null;
};

export type ReasoningEffort = 'minimal' | 'low' | 'medium' | 'high';

export type RedirectResponse = {
    /**
     * The URL to redirect to (OAuth authorization URL or application home page)
     */
    location: string;
};

export type ResourceRole = 'resource_user' | 'resource_power_user' | 'resource_manager' | 'resource_admin';

export type ResponseFormat = {
    type: 'text';
} | {
    type: 'json_object';
} | {
    json_schema: ResponseFormatJsonSchema;
    type: 'json_schema';
};

export type ResponseFormatJsonSchema = {
    /**
     * A description of what the response format is for, used by the model to determine how to respond in the format.
     */
    description?: string | null;
    /**
     * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: string;
    /**
     * The schema for the response format, described as a JSON Schema object.
     */
    schema?: unknown;
    /**
     * Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the `schema` field. Only a subset of JSON Schema is supported when `strict` is `true`. To learn more, read the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).
     */
    strict?: boolean | null;
};

export type Role = 'system' | 'user' | 'assistant' | 'tool' | 'function';

export type ServiceTier = 'auto' | 'default' | 'flex' | 'scale' | 'priority';

export type ServiceTierResponse = 'scale' | 'default' | 'flex' | 'priority';

export type SettingInfo = {
    key: string;
    current_value: unknown;
    default_value: unknown;
    source: SettingSource;
    metadata: SettingMetadata;
};

export type SettingMetadata = {
    type: 'string';
} | {
    min: number;
    max: number;
    type: 'number';
} | {
    type: 'boolean';
} | {
    options: Array<string>;
    type: 'option';
};

export type SettingSource = 'system' | 'command_line' | 'environment' | 'settings_file' | 'default';

/**
 * Request to setup the application in authenticated mode
 */
export type SetupRequest = {
    /**
     * Server name for identification (minimum 10 characters)
     */
    name: string;
    /**
     * Optional description of the server's purpose
     */
    description?: string | null;
};

/**
 * Response containing the updated application status after setup
 */
export type SetupResponse = {
    /**
     * New application status after successful setup
     */
    status: AppStatus;
};

export type ShowRequest = {
    name: string;
};

export type ShowResponse = {
    details: ModelDetails;
    license: string;
    model_info: {};
    modelfile: string;
    modified_at: number;
    parameters: string;
    template: string;
};

export type Stop = string | Array<string>;

/**
 * Credentials for test/fetch operations
 */
export type TestCreds = {
    /**
     * Look up credentials from stored API model
     */
    value: string;
    type: 'id';
} | {
    /**
     * Use direct API key (null for no authentication)
     */
    value: ApiKey;
    type: 'api_key';
};

/**
 * Request to test API connectivity with a prompt
 */
export type TestPromptRequest = {
    /**
     * Credentials to use for testing
     */
    creds?: TestCreds;
    /**
     * API base URL
     */
    base_url: string;
    /**
     * Model to use for testing
     */
    model: string;
    /**
     * Test prompt (max 30 characters for cost control)
     */
    prompt: string;
};

/**
 * Response from testing API connectivity
 */
export type TestPromptResponse = {
    success: boolean;
    response?: string | null;
    error?: string | null;
};

/**
 * API Token information response
 */
export type TokenInfo = {
    role: TokenScope;
};

export type TokenScope = 'scope_token_user' | 'scope_token_power_user' | 'scope_token_manager' | 'scope_token_admin';

export type TokenStatus = 'active' | 'inactive';

export type TopLogprobs = {
    /**
     * The token.
     */
    token: string;
    /**
     * The log probability of this token.
     */
    logprob: number;
    /**
     * A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
     */
    bytes?: Array<number> | null;
};

export type UpdateAliasRequest = {
    repo: string;
    filename: string;
    snapshot?: string | null;
    request_params?: null | OaiRequestParams;
    context_params?: Array<string> | null;
};

/**
 * Request to update an existing API model configuration
 */
export type UpdateApiModelRequest = {
    /**
     * API format/protocol (required)
     */
    api_format: ApiFormat;
    /**
     * API base URL (required)
     */
    base_url: string;
    /**
     * API key update action (Keep/Set with Some or None)
     */
    api_key?: ApiKeyUpdateAction;
    /**
     * List of available models (required)
     */
    models: Array<string>;
    /**
     * Optional prefix for model namespacing
     */
    prefix?: string | null;
};

/**
 * Request to update an existing API token
 */
export type UpdateApiTokenRequest = {
    /**
     * New descriptive name for the token (minimum 3 characters)
     */
    name: string;
    /**
     * New status for the token (active/inactive)
     */
    status: TokenStatus;
};

/**
 * Request to update a setting value
 */
export type UpdateSettingRequest = {
    /**
     * New value for the setting (type depends on setting metadata)
     */
    value: unknown;
};

export type UserAccessRequest = {
    /**
     * Unique identifier for the request
     */
    id: number;
    /**
     * Username of the requesting user
     */
    username: string;
    /**
     * User ID (UUID) of the requesting user
     */
    user_id: string;
    reviewer?: string | null;
    /**
     * Current status of the request
     */
    status: UserAccessRequestStatus;
    /**
     * Creation timestamp
     */
    created_at: string;
    /**
     * Last update timestamp
     */
    updated_at: string;
};

export type UserAccessRequestStatus = 'pending' | 'approved' | 'rejected';

/**
 * Response for checking access request status
 */
export type UserAccessStatusResponse = {
    /**
     * Username of the requesting user
     */
    username: string;
    /**
     * Current status of the request (pending, approved, rejected)
     */
    status: UserAccessRequestStatus;
    /**
     * Creation timestamp
     */
    created_at: string;
    /**
     * Last update timestamp
     */
    updated_at: string;
};

export type UserAlias = {
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
    request_params?: OaiRequestParams;
    context_params?: Array<string>;
};

export type UserAliasResponse = {
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
    source: string;
    model_params: {};
    request_params: OaiRequestParams;
    context_params: Array<string>;
};

export type UserInfo = {
    user_id: string;
    username: string;
    first_name?: string | null;
    last_name?: string | null;
    role?: null | AppRole;
};

export type UserListResponse = {
    client_id: string;
    users: Array<UserInfo>;
    page: number;
    page_size: number;
    total_pages: number;
    total_users: number;
    has_next: boolean;
    has_previous: boolean;
};

/**
 * User authentication response with discriminated union
 */
export type UserResponse = {
    auth_status: 'logged_out';
} | (UserInfo & {
    auth_status: 'logged_in';
}) | (TokenInfo & {
    auth_status: 'api_token';
});

export type UserScope = 'scope_user_user' | 'scope_user_power_user' | 'scope_user_manager' | 'scope_user_admin';

/**
 * The amount of context window space to use for the search.
 */
export type WebSearchContextSize = 'low' | 'medium' | 'high';

/**
 * Approximate location parameters for the search.
 */
export type WebSearchLocation = {
    /**
     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.
     */
    country?: string | null;
    /**
     * Free text input for the region of the user, e.g. `California`.
     */
    region?: string | null;
    /**
     * Free text input for the city of the user, e.g. `San Francisco`.
     */
    city?: string | null;
    /**
     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.
     */
    timezone?: string | null;
};

/**
 * Options for the web search tool.
 */
export type WebSearchOptions = {
    search_context_size?: null | WebSearchContextSize;
    user_location?: null | WebSearchUserLocation;
};

export type WebSearchUserLocation = {
    type: WebSearchUserLocationType;
    approximate: WebSearchLocation;
};

export type WebSearchUserLocationType = 'approximate';

export type ChatOllamaModelData = {
    /**
     * Chat request in Ollama format
     */
    body: ChatRequest;
    path?: never;
    query?: never;
    url: '/api/chat';
};

export type ChatOllamaModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model not found
     */
    404: OllamaError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ChatOllamaModelError = ChatOllamaModelErrors[keyof ChatOllamaModelErrors];

export type ChatOllamaModelResponses = {
    /**
     * Chat response
     */
    200: unknown;
};

export type ShowOllamaModelData = {
    /**
     * Model name to get details for
     */
    body: ShowRequest;
    path?: never;
    query?: never;
    url: '/api/show';
};

export type ShowOllamaModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model not found
     */
    404: OllamaError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ShowOllamaModelError = ShowOllamaModelErrors[keyof ShowOllamaModelErrors];

export type ShowOllamaModelResponses = {
    /**
     * Model details
     */
    200: ShowResponse;
};

export type ShowOllamaModelResponse = ShowOllamaModelResponses[keyof ShowOllamaModelResponses];

export type ListOllamaModelsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/api/tags';
};

export type ListOllamaModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListOllamaModelsError = ListOllamaModelsErrors[keyof ListOllamaModelsErrors];

export type ListOllamaModelsResponses = {
    /**
     * List of available models
     */
    200: ModelsResponse;
};

export type ListOllamaModelsResponse = ListOllamaModelsResponses[keyof ListOllamaModelsResponses];

export type ListAllAccessRequestsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/access-requests';
};

export type ListAllAccessRequestsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListAllAccessRequestsError = ListAllAccessRequestsErrors[keyof ListAllAccessRequestsErrors];

export type ListAllAccessRequestsResponses = {
    /**
     * All requests retrieved
     */
    200: PaginatedUserAccessResponse;
};

export type ListAllAccessRequestsResponse = ListAllAccessRequestsResponses[keyof ListAllAccessRequestsResponses];

export type ListPendingAccessRequestsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/access-requests/pending';
};

export type ListPendingAccessRequestsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListPendingAccessRequestsError = ListPendingAccessRequestsErrors[keyof ListPendingAccessRequestsErrors];

export type ListPendingAccessRequestsResponses = {
    /**
     * Pending requests retrieved
     */
    200: PaginatedUserAccessResponse;
};

export type ListPendingAccessRequestsResponse = ListPendingAccessRequestsResponses[keyof ListPendingAccessRequestsResponses];

export type ApproveAccessRequestData = {
    /**
     * Role to assign to the user
     */
    body: ApproveUserAccessRequest;
    path: {
        /**
         * Access request ID
         */
        id: number;
    };
    query?: never;
    url: '/bodhi/v1/access-requests/{id}/approve';
};

export type ApproveAccessRequestErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ApproveAccessRequestError = ApproveAccessRequestErrors[keyof ApproveAccessRequestErrors];

export type ApproveAccessRequestResponses = {
    /**
     * Request approved successfully
     */
    200: unknown;
};

export type RejectAccessRequestData = {
    body?: never;
    path: {
        /**
         * Access request ID
         */
        id: number;
    };
    query?: never;
    url: '/bodhi/v1/access-requests/{id}/reject';
};

export type RejectAccessRequestErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RejectAccessRequestError = RejectAccessRequestErrors[keyof RejectAccessRequestErrors];

export type RejectAccessRequestResponses = {
    /**
     * Request rejected successfully
     */
    200: unknown;
};

export type ListApiModelsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/api-models';
};

export type ListApiModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListApiModelsError = ListApiModelsErrors[keyof ListApiModelsErrors];

export type ListApiModelsResponses = {
    /**
     * API model configurations retrieved successfully
     */
    200: PaginatedApiModelResponse;
};

export type ListApiModelsResponse = ListApiModelsResponses[keyof ListApiModelsResponses];

export type CreateApiModelData = {
    body: CreateApiModelRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models';
};

export type CreateApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Alias already exists
     */
    409: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateApiModelError = CreateApiModelErrors[keyof CreateApiModelErrors];

export type CreateApiModelResponses = {
    /**
     * API model created
     */
    201: ApiModelResponse;
};

export type CreateApiModelResponse = CreateApiModelResponses[keyof CreateApiModelResponses];

export type GetApiFormatsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models/api-formats';
};

export type GetApiFormatsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetApiFormatsError = GetApiFormatsErrors[keyof GetApiFormatsErrors];

export type GetApiFormatsResponses = {
    /**
     * API formats retrieved successfully
     */
    200: ApiFormatsResponse;
};

export type GetApiFormatsResponse = GetApiFormatsResponses[keyof GetApiFormatsResponses];

export type FetchApiModelsData = {
    body: FetchModelsRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models/fetch-models';
};

export type FetchApiModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type FetchApiModelsError = FetchApiModelsErrors[keyof FetchApiModelsErrors];

export type FetchApiModelsResponses = {
    /**
     * Available models
     */
    200: FetchModelsResponse;
};

export type FetchApiModelsResponse = FetchApiModelsResponses[keyof FetchApiModelsResponses];

export type TestApiModelData = {
    body: TestPromptRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models/test';
};

export type TestApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type TestApiModelError = TestApiModelErrors[keyof TestApiModelErrors];

export type TestApiModelResponses = {
    /**
     * Test result
     */
    200: TestPromptResponse;
};

export type TestApiModelResponse = TestApiModelResponses[keyof TestApiModelResponses];

export type DeleteApiModelData = {
    body?: never;
    path: {
        /**
         * API model ID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}';
};

export type DeleteApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type DeleteApiModelError = DeleteApiModelErrors[keyof DeleteApiModelErrors];

export type DeleteApiModelResponses = {
    /**
     * API model deleted
     */
    204: void;
};

export type DeleteApiModelResponse = DeleteApiModelResponses[keyof DeleteApiModelResponses];

export type GetApiModelData = {
    body?: never;
    path: {
        /**
         * Unique identifier for the API model alias
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}';
};

export type GetApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model with specified ID not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetApiModelError = GetApiModelErrors[keyof GetApiModelErrors];

export type GetApiModelResponses = {
    /**
     * API model configuration retrieved successfully
     */
    200: ApiModelResponse;
};

export type GetApiModelResponse = GetApiModelResponses[keyof GetApiModelResponses];

export type UpdateApiModelData = {
    body: UpdateApiModelRequest;
    path: {
        /**
         * API model ID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}';
};

export type UpdateApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateApiModelError = UpdateApiModelErrors[keyof UpdateApiModelErrors];

export type UpdateApiModelResponses = {
    /**
     * API model updated
     */
    200: ApiModelResponse;
};

export type UpdateApiModelResponse = UpdateApiModelResponses[keyof UpdateApiModelResponses];

export type RequestAccessData = {
    /**
     * Application client requesting access
     */
    body: AppAccessRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/apps/request-access';
};

export type RequestAccessErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RequestAccessError = RequestAccessErrors[keyof RequestAccessErrors];

export type RequestAccessResponses = {
    /**
     * Access granted successfully
     */
    200: AppAccessResponse;
};

export type RequestAccessResponse = RequestAccessResponses[keyof RequestAccessResponses];

export type CompleteOAuthFlowData = {
    /**
     * OAuth callback parameters from authorization server
     */
    body: AuthCallbackRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/auth/callback';
};

export type CompleteOAuthFlowErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * OAuth error, invalid request parameters, or state mismatch
     */
    422: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CompleteOAuthFlowError = CompleteOAuthFlowErrors[keyof CompleteOAuthFlowErrors];

export type CompleteOAuthFlowResponses = {
    /**
     * OAuth flow completed successfully, user authenticated
     */
    200: RedirectResponse;
};

export type CompleteOAuthFlowResponse = CompleteOAuthFlowResponses[keyof CompleteOAuthFlowResponses];

export type InitiateOAuthFlowData = {
    body: unknown;
    path?: never;
    query?: never;
    url: '/bodhi/v1/auth/initiate';
};

export type InitiateOAuthFlowErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type InitiateOAuthFlowError = InitiateOAuthFlowErrors[keyof InitiateOAuthFlowErrors];

export type InitiateOAuthFlowResponses = {
    /**
     * User already authenticated, home page URL provided
     */
    200: RedirectResponse;
    /**
     * User not authenticated, OAuth authorization URL provided
     */
    201: RedirectResponse;
};

export type InitiateOAuthFlowResponse = InitiateOAuthFlowResponses[keyof InitiateOAuthFlowResponses];

export type GetAppInfoData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/info';
};

export type GetAppInfoErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetAppInfoError = GetAppInfoErrors[keyof GetAppInfoErrors];

export type GetAppInfoResponses = {
    /**
     * Application information retrieved successfully
     */
    200: AppInfo;
};

export type GetAppInfoResponse = GetAppInfoResponses[keyof GetAppInfoResponses];

export type LogoutUserData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/logout';
};

export type LogoutUserErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type LogoutUserError = LogoutUserErrors[keyof LogoutUserErrors];

export type LogoutUserResponses = {
    /**
     * User logged out successfully
     */
    200: RedirectResponse;
};

export type LogoutUserResponse = LogoutUserResponses[keyof LogoutUserResponses];

export type ListModelFilesData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/modelfiles';
};

export type ListModelFilesErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListModelFilesError = ListModelFilesErrors[keyof ListModelFilesErrors];

export type ListModelFilesResponses = {
    /**
     * Local model files retrieved successfully from cache
     */
    200: PaginatedLocalModelResponse;
};

export type ListModelFilesResponse = ListModelFilesResponses[keyof ListModelFilesResponses];

export type ListDownloadsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/modelfiles/pull';
};

export type ListDownloadsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListDownloadsError = ListDownloadsErrors[keyof ListDownloadsErrors];

export type ListDownloadsResponses = {
    /**
     * Model download requests retrieved successfully
     */
    200: PaginatedDownloadResponse;
};

export type ListDownloadsResponse = ListDownloadsResponses[keyof ListDownloadsResponses];

export type PullModelFileData = {
    /**
     * Model file download specification with repository and filename
     */
    body: NewDownloadRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/modelfiles/pull';
};

export type PullModelFileErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type PullModelFileError = PullModelFileErrors[keyof PullModelFileErrors];

export type PullModelFileResponses = {
    /**
     * Existing download request found
     */
    200: DownloadRequest;
    /**
     * Download request created
     */
    201: DownloadRequest;
};

export type PullModelFileResponse = PullModelFileResponses[keyof PullModelFileResponses];

export type PullModelByAliasData = {
    body?: never;
    path: {
        /**
         * Predefined model alias. Available aliases include popular models like llama2:chat, mistral:instruct, phi3:mini, etc. Use the /models endpoint to see all available aliases.
         */
        alias: string;
    };
    query?: never;
    url: '/bodhi/v1/modelfiles/pull/{alias}';
};

export type PullModelByAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Alias not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type PullModelByAliasError = PullModelByAliasErrors[keyof PullModelByAliasErrors];

export type PullModelByAliasResponses = {
    /**
     * Existing download request found
     */
    200: DownloadRequest;
    /**
     * Download request created
     */
    201: DownloadRequest;
};

export type PullModelByAliasResponse = PullModelByAliasResponses[keyof PullModelByAliasResponses];

export type GetDownloadStatusData = {
    body?: never;
    path: {
        /**
         * Unique identifier of the download request (UUID format)
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/modelfiles/pull/{id}';
};

export type GetDownloadStatusErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Download request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetDownloadStatusError = GetDownloadStatusErrors[keyof GetDownloadStatusErrors];

export type GetDownloadStatusResponses = {
    /**
     * Download request found
     */
    200: DownloadRequest;
};

export type GetDownloadStatusResponse = GetDownloadStatusResponses[keyof GetDownloadStatusResponses];

export type ListAllModelsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/models';
};

export type ListAllModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListAllModelsError = ListAllModelsErrors[keyof ListAllModelsErrors];

export type ListAllModelsResponses = {
    /**
     * Paginated list of model aliases retrieved successfully
     */
    200: PaginatedAliasResponse;
};

export type ListAllModelsResponse = ListAllModelsResponses[keyof ListAllModelsResponses];

export type CreateAliasData = {
    body: CreateAliasRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/models';
};

export type CreateAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateAliasError = CreateAliasErrors[keyof CreateAliasErrors];

export type CreateAliasResponses = {
    /**
     * Alias created succesfully
     */
    201: UserAliasResponse;
};

export type CreateAliasResponse = CreateAliasResponses[keyof CreateAliasResponses];

export type GetAliasData = {
    body?: never;
    path: {
        /**
         * Alias identifier for the model
         */
        alias: string;
    };
    query?: never;
    url: '/bodhi/v1/models/{alias}';
};

export type GetAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Alias not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetAliasError = GetAliasErrors[keyof GetAliasErrors];

export type GetAliasResponses = {
    /**
     * Model alias details
     */
    200: UserAliasResponse;
};

export type GetAliasResponse = GetAliasResponses[keyof GetAliasResponses];

export type UpdateAliasData = {
    body: UpdateAliasRequest;
    path: {
        /**
         * Alias identifier
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/models/{id}';
};

export type UpdateAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateAliasError = UpdateAliasErrors[keyof UpdateAliasErrors];

export type UpdateAliasResponses = {
    /**
     * Alias updated succesfully
     */
    200: UserAliasResponse;
};

export type UpdateAliasResponse = UpdateAliasResponses[keyof UpdateAliasResponses];

export type ListSettingsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/settings';
};

export type ListSettingsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListSettingsError = ListSettingsErrors[keyof ListSettingsErrors];

export type ListSettingsResponses = {
    /**
     * Application settings retrieved successfully
     */
    200: Array<SettingInfo>;
};

export type ListSettingsResponse = ListSettingsResponses[keyof ListSettingsResponses];

export type DeleteSettingData = {
    body?: never;
    path: {
        /**
         * Setting key identifier to reset to default value
         */
        key: string;
    };
    query?: never;
    url: '/bodhi/v1/settings/{key}';
};

export type DeleteSettingErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Setting not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type DeleteSettingError = DeleteSettingErrors[keyof DeleteSettingErrors];

export type DeleteSettingResponses = {
    /**
     * Setting reset to default successfully
     */
    200: SettingInfo;
};

export type DeleteSettingResponse = DeleteSettingResponses[keyof DeleteSettingResponses];

export type UpdateSettingData = {
    /**
     * Request to update a setting value
     */
    body: {
        /**
         * New value for the setting (type depends on setting metadata)
         */
        value: unknown;
    };
    path: {
        /**
         * Setting key identifier (e.g., BODHI_LOG_LEVEL, BODHI_PORT)
         */
        key: string;
    };
    query?: never;
    url: '/bodhi/v1/settings/{key}';
};

export type UpdateSettingErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Setting not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateSettingError = UpdateSettingErrors[keyof UpdateSettingErrors];

export type UpdateSettingResponses = {
    /**
     * Setting updated successfully
     */
    200: SettingInfo;
};

export type UpdateSettingResponse = UpdateSettingResponses[keyof UpdateSettingResponses];

export type SetupAppData = {
    /**
     * Application setup configuration
     */
    body: SetupRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/setup';
};

export type SetupAppErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type SetupAppError = SetupAppErrors[keyof SetupAppErrors];

export type SetupAppResponses = {
    /**
     * Application setup completed successfully
     */
    200: SetupResponse;
};

export type SetupAppResponse = SetupAppResponses[keyof SetupAppResponses];

export type ListApiTokensData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/tokens';
};

export type ListApiTokensErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListApiTokensError = ListApiTokensErrors[keyof ListApiTokensErrors];

export type ListApiTokensResponses = {
    /**
     * List of API tokens
     */
    200: PaginatedApiTokenResponse;
};

export type ListApiTokensResponse = ListApiTokensResponses[keyof ListApiTokensResponses];

export type CreateApiTokenData = {
    /**
     * API token creation parameters
     */
    body: CreateApiTokenRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/tokens';
};

export type CreateApiTokenErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateApiTokenError = CreateApiTokenErrors[keyof CreateApiTokenErrors];

export type CreateApiTokenResponses = {
    /**
     * API token created successfully
     */
    201: ApiTokenResponse;
};

export type CreateApiTokenResponse = CreateApiTokenResponses[keyof CreateApiTokenResponses];

export type UpdateApiTokenData = {
    /**
     * Token update request
     */
    body: UpdateApiTokenRequest;
    path: {
        /**
         * Unique identifier of the API token to update
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/tokens/{id}';
};

export type UpdateApiTokenErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Token not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateApiTokenError = UpdateApiTokenErrors[keyof UpdateApiTokenErrors];

export type UpdateApiTokenResponses = {
    /**
     * Token updated successfully
     */
    200: ApiToken;
};

export type UpdateApiTokenResponse = UpdateApiTokenResponses[keyof UpdateApiTokenResponses];

export type GetCurrentUserData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/user';
};

export type GetCurrentUserErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetCurrentUserError = GetCurrentUserErrors[keyof GetCurrentUserErrors];

export type GetCurrentUserResponses = {
    /**
     * User information (authenticated or not)
     */
    200: UserResponse;
};

export type GetCurrentUserResponse = GetCurrentUserResponses[keyof GetCurrentUserResponses];

export type RequestUserAccessData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/user/request-access';
};

export type RequestUserAccessErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Pending request already exists
     */
    409: OpenAiApiError;
    /**
     * User already has role
     */
    422: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RequestUserAccessError = RequestUserAccessErrors[keyof RequestUserAccessErrors];

export type RequestUserAccessResponses = {
    /**
     * Access request created successfully
     */
    201: unknown;
};

export type GetUserAccessStatusData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/user/request-status';
};

export type GetUserAccessStatusErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetUserAccessStatusError = GetUserAccessStatusErrors[keyof GetUserAccessStatusErrors];

export type GetUserAccessStatusResponses = {
    /**
     * Request status retrieved
     */
    200: UserAccessStatusResponse;
};

export type GetUserAccessStatusResponse = GetUserAccessStatusResponses[keyof GetUserAccessStatusResponses];

export type ListUsersData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based)
         */
        page?: number;
        /**
         * Number of users per page
         */
        page_size?: number;
    };
    url: '/bodhi/v1/users';
};

export type ListUsersErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListUsersError = ListUsersErrors[keyof ListUsersErrors];

export type ListUsersResponses = {
    /**
     * Users retrieved successfully
     */
    200: UserListResponse;
};

export type ListUsersResponse = ListUsersResponses[keyof ListUsersResponses];

export type RemoveUserData = {
    body?: never;
    path: {
        /**
         * User ID to remove
         */
        user_id: string;
    };
    query?: never;
    url: '/bodhi/v1/users/{user_id}';
};

export type RemoveUserErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * User not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RemoveUserError = RemoveUserErrors[keyof RemoveUserErrors];

export type RemoveUserResponses = {
    /**
     * User removed successfully
     */
    200: unknown;
};

export type ChangeUserRoleData = {
    body: ChangeRoleRequest;
    path: {
        /**
         * User ID to change role for
         */
        user_id: string;
    };
    query?: never;
    url: '/bodhi/v1/users/{user_id}/role';
};

export type ChangeUserRoleErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * User not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ChangeUserRoleError = ChangeUserRoleErrors[keyof ChangeUserRoleErrors];

export type ChangeUserRoleResponses = {
    /**
     * Role changed successfully
     */
    200: unknown;
};

export type HealthCheckData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/health';
};

export type HealthCheckErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type HealthCheckError = HealthCheckErrors[keyof HealthCheckErrors];

export type HealthCheckResponses = {
    /**
     * Application is healthy and fully operational
     */
    200: PingResponse;
};

export type HealthCheckResponse = HealthCheckResponses[keyof HealthCheckResponses];

export type PingServerData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/ping';
};

export type PingServerErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type PingServerError = PingServerErrors[keyof PingServerErrors];

export type PingServerResponses = {
    /**
     * Server is responding normally
     */
    200: PingResponse;
};

export type PingServerResponse = PingServerResponses[keyof PingServerResponses];

export type CreateChatCompletionData = {
    body: CreateChatCompletionRequest;
    path?: never;
    query?: never;
    url: '/v1/chat/completions';
};

export type CreateChatCompletionErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateChatCompletionError = CreateChatCompletionErrors[keyof CreateChatCompletionErrors];

export type CreateChatCompletionResponses = {
    /**
     * Chat completion response
     */
    200: CreateChatCompletionResponse;
    /**
     * Chat completion stream, the status is 200, using 201 to avoid OpenAPI format limitation.
     */
    201: CreateChatCompletionStreamResponse;
};

export type CreateChatCompletionResponse2 = CreateChatCompletionResponses[keyof CreateChatCompletionResponses];

export type CreateEmbeddingData = {
    body: CreateEmbeddingRequest;
    path?: never;
    query?: never;
    url: '/v1/embeddings';
};

export type CreateEmbeddingErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateEmbeddingError = CreateEmbeddingErrors[keyof CreateEmbeddingErrors];

export type CreateEmbeddingResponses = {
    /**
     * Embedding response
     */
    200: CreateEmbeddingResponse;
};

export type CreateEmbeddingResponse2 = CreateEmbeddingResponses[keyof CreateEmbeddingResponses];

export type ListModelsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/v1/models';
};

export type ListModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListModelsError = ListModelsErrors[keyof ListModelsErrors];

export type ListModelsResponses = {
    /**
     * List of available models
     */
    200: ListModelResponse;
};

export type ListModelsResponse = ListModelsResponses[keyof ListModelsResponses];

export type GetModelData = {
    body?: never;
    path: {
        /**
         * Model identifier - can be user alias (e.g., 'llama2:chat'), model alias, or API provider alias
         */
        id: string;
    };
    query?: never;
    url: '/v1/models/{id}';
};

export type GetModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetModelError = GetModelErrors[keyof GetModelErrors];

export type GetModelResponses = {
    /**
     * Model details
     */
    200: ModelResponse;
};

export type GetModelResponse = GetModelResponses[keyof GetModelResponses];

export type ClientOptions = {
    baseUrl: 'http://localhost:1135' | (string & {});
};