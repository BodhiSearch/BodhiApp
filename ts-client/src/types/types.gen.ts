// This file is auto-generated by @hey-api/openapi-ts

/**
 * Flat enum representing all types of model aliases
 * Each variant is identified by the source field
 */
export type Alias = (UserAlias & {
    source: 'user';
}) | (ModelAlias & {
    source: 'model';
}) | (ApiAlias & {
    source: 'api';
});

/**
 * Response envelope for model aliases - hides internal implementation details
 * Uses untagged serialization - each variant has its own "source" field
 */
export type AliasResponse = UserAliasResponse | ModelAliasResponse | ApiAliasResponse;

export type ApiAlias = {
    id: string;
    api_format: ApiFormat;
    base_url: string;
    models: Array<string>;
    prefix?: string | null;
    forward_all_with_prefix: boolean;
    models_cache: Array<string>;
    cache_fetched_at: string;
    created_at: string;
    updated_at: string;
};

/**
 * API response for API model aliases - hides internal cache fields
 */
export type ApiAliasResponse = {
    source: string;
    id: string;
    api_format: ApiFormat;
    base_url: string;
    /**
     * Models available through this alias (merged from cache for forward_all)
     */
    models: Array<string>;
    prefix?: string | null;
    forward_all_with_prefix: boolean;
    created_at: string;
    updated_at: string;
};

/**
 * API format/protocol specification
 */
export type ApiFormat = 'openai' | 'placeholder';

/**
 * Response containing available API formats
 */
export type ApiFormatsResponse = {
    data: Array<ApiFormat>;
};

/**
 * Validated API key wrapper - validates length when Some, allows None for public APIs
 */
export type ApiKey = string | null;

/**
 * Represents an API key update action for API model updates
 */
export type ApiKeyUpdateAction = {
    action: 'keep';
} | {
    /**
     * Set a new API key (or add one if none exists) - can be None for public APIs
     */
    value: ApiKey;
    action: 'set';
};

/**
 * API key update enum (mirrors services::db::ApiKeyUpdate)
 */
export type ApiKeyUpdateDto = {
    action: 'Keep';
} | {
    /**
     * Set a new API key (or clear if None)
     */
    value: string | null;
    action: 'Set';
};

/**
 * Response containing API model configuration
 */
export type ApiModelResponse = {
    id: string;
    api_format: ApiFormat;
    base_url: string;
    api_key_masked?: string | null;
    models: Array<string>;
    prefix?: string | null;
    forward_all_with_prefix: boolean;
    created_at: string;
    updated_at: string;
};

export type ApiToken = {
    id: string;
    user_id: string;
    name: string;
    token_prefix: string;
    token_hash: string;
    scopes: string;
    status: TokenStatus;
    created_at: string;
    updated_at: string;
};

export type ApiTokenResponse = {
    /**
     * API token with bodhiapp_ prefix for programmatic access
     */
    token: string;
};

export type AppAccessRequest = {
    app_client_id: string;
    /**
     * Optional version for cache lookup - if matches cached config, skips auth server call
     */
    version?: string | null;
    /**
     * Optional toolset scope IDs to register with resource-client for token exchange
     */
    toolset_scope_ids?: Array<string> | null;
};

export type AppAccessResponse = {
    scope: string;
    /**
     * List of toolsets the app-client is configured to access
     */
    toolsets?: Array<AppClientToolset>;
    /**
     * Version of app-client's toolset configuration on auth server
     */
    app_client_config_version?: string | null;
};

/**
 * Toolset configuration from app-client registration
 */
export type AppClientToolset = {
    id: string;
    scope: string;
    /**
     * client scope UUID for cache validation
     */
    scope_id?: string;
    /**
     * True if scope has been added to resource-client as optional scope
     */
    added_to_resource_client?: boolean | null;
};

/**
 * Application information and status
 */
export type AppInfo = {
    /**
     * Application version number (semantic versioning)
     */
    version: string;
    /**
     * Git commit SHA of the build
     */
    commit_sha: string;
    /**
     * Current application setup and operational status
     */
    status: AppStatus;
};

export type AppRole = ResourceRole | TokenScope | UserScope;

export type AppStatus = 'setup' | 'ready' | 'resource-admin';

/**
 * App-level configuration for a toolset (admin-controlled)
 */
export type AppToolsetConfig = {
    /**
     * Toolset identifier (e.g., "builtin-exa-web-search")
     */
    toolset_id: string;
    /**
     * Whether the toolset is enabled for this app instance
     */
    enabled: boolean;
    /**
     * User ID of the admin who last updated this configuration
     */
    updated_by: string;
    /**
     * When this configuration was created
     */
    created_at: string;
    /**
     * When this configuration was last updated
     */
    updated_at: string;
};

/**
 * The app-level toolset configuration
 */
export type AppToolsetConfigResponse = AppToolsetConfig;

/**
 * Request body for approving access with role assignment
 */
export type ApproveUserAccessRequest = {
    /**
     * Role to assign to the user
     */
    role: ResourceRole;
};

export type AuthCallbackRequest = {
    /**
     * OAuth authorization code from successful authentication (required for success flow)
     */
    code?: string | null;
    /**
     * OAuth state parameter for CSRF protection (must match initiated request)
     */
    state?: string | null;
    /**
     * OAuth error code if authentication failed (e.g., "access_denied")
     */
    error?: string | null;
    /**
     * Human-readable OAuth error description if authentication failed
     */
    error_description?: string | null;
    [key: string]: string | (string | null) | (string | null) | (string | null) | (string | null) | undefined;
};

/**
 * Change user role request
 */
export type ChangeRoleRequest = {
    /**
     * Role to assign to the user
     */
    role: string;
};

export type ChatChoice = {
    /**
     * The index of the choice in the list of choices.
     */
    index: number;
    message: ChatCompletionResponseMessage;
    finish_reason?: null | FinishReason;
    logprobs?: null | ChatChoiceLogprobs;
};

export type ChatChoiceLogprobs = {
    /**
     * A list of message content tokens with log probability information.
     */
    content?: Array<ChatCompletionTokenLogprob> | null;
    refusal?: Array<ChatCompletionTokenLogprob> | null;
};

export type ChatChoiceStream = {
    /**
     * The index of the choice in the list of choices.
     */
    index: number;
    delta: ChatCompletionStreamResponseDelta;
    finish_reason?: null | FinishReason;
    logprobs?: null | ChatChoiceLogprobs;
};

export type ChatCompletionAllowedTools = {
    /**
     * Constrains the tools available to the model to a pre-defined set.
     *
     * `auto` allows the model to pick from among the allowed tools and generate a
     * message.
     *
     * `required` requires the model to call one or more of the allowed tools.
     */
    mode: ToolChoiceAllowedMode;
    /**
     * A list of tool definitions that the model should be allowed to call.
     *
     * For the Chat Completions API, the list of tool definitions might look like:
     * ```json
     * [
     * { "type": "function", "function": { "name": "get_weather" } },
     * { "type": "function", "function": { "name": "get_time" } }
     * ]
     * ```
     */
    tools: Array<unknown>;
};

export type ChatCompletionAllowedToolsChoice = {
    allowed_tools: Array<ChatCompletionAllowedTools>;
};

export type ChatCompletionAudio = {
    /**
     * The voice the model uses to respond. Supported built-in voices are `alloy`, `ash`,
     * `ballad`, `coral`, `echo`, `fable`, `nova`, `onyx`, `sage`, `shimmer`, `marin`, and `cedar`.
     */
    voice: ChatCompletionAudioVoice;
    /**
     * Specifies the output audio format. Must be one of `wav`, `aac`, `mp3`, `flac`, `opus`, or `pcm16`.
     */
    format: ChatCompletionAudioFormat;
};

export type ChatCompletionAudioFormat = 'wav' | 'aac' | 'mp3' | 'flac' | 'opus' | 'pcm16';

export type ChatCompletionAudioVoice = 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'fable' | 'nova' | 'onyx' | 'sage' | 'shimmer' | {
    other: string;
};

export type ChatCompletionFunctionCall = 'none' | 'auto' | {
    /**
     * Forces the model to call the specified function.
     */
    Function: {
        name: string;
    };
};

export type ChatCompletionFunctions = {
    /**
     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: string;
    /**
     * A description of what the function does, used by the model to choose when and how to call the function.
     */
    description?: string | null;
    /**
     * The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
     *
     * Omitting `parameters` defines a function with an empty parameter list.
     */
    parameters: unknown;
};

export type ChatCompletionMessageCustomToolCall = {
    /**
     * The ID of the tool call.
     */
    id: string;
    /**
     * The custom tool that the model called.
     */
    custom_tool: CustomTool;
};

export type ChatCompletionMessageToolCall = {
    /**
     * The ID of the tool call.
     */
    id: string;
    /**
     * The function that the model called.
     */
    function: FunctionCall;
};

export type ChatCompletionMessageToolCallChunk = {
    index: number;
    /**
     * The ID of the tool call.
     */
    id?: string | null;
    type?: null | FunctionType;
    function?: null | FunctionCallStream;
};

export type ChatCompletionMessageToolCalls = (ChatCompletionMessageToolCall & {
    type: 'function';
}) | (ChatCompletionMessageCustomToolCall & {
    type: 'custom';
});

/**
 * Specifies a tool the model should use. Use to force the model to call a specific function.
 */
export type ChatCompletionNamedToolChoice = {
    function: FunctionName;
};

export type ChatCompletionNamedToolChoiceCustom = {
    custom: CustomName;
};

export type ChatCompletionRequestAssistantMessage = {
    content?: null | ChatCompletionRequestAssistantMessageContent;
    /**
     * The refusal message by the assistant.
     */
    refusal?: string | null;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
    audio?: null | ChatCompletionRequestAssistantMessageAudio;
    tool_calls?: Array<ChatCompletionMessageToolCalls> | null;
    function_call?: null | FunctionCall;
};

export type ChatCompletionRequestAssistantMessageAudio = {
    /**
     * Unique identifier for a previous audio response from the model.
     */
    id: string;
};

export type ChatCompletionRequestAssistantMessageContent = string | Array<ChatCompletionRequestAssistantMessageContentPart>;

export type ChatCompletionRequestAssistantMessageContentPart = (ChatCompletionRequestMessageContentPartText & {
    type: 'text';
}) | (ChatCompletionRequestMessageContentPartRefusal & {
    type: 'refusal';
});

export type ChatCompletionRequestDeveloperMessage = {
    /**
     * The contents of the developer message.
     */
    content: ChatCompletionRequestDeveloperMessageContent;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
};

export type ChatCompletionRequestDeveloperMessageContent = string | Array<ChatCompletionRequestDeveloperMessageContentPart>;

export type ChatCompletionRequestDeveloperMessageContentPart = ChatCompletionRequestMessageContentPartText & {
    type: 'text';
};

export type ChatCompletionRequestFunctionMessage = {
    /**
     * The return value from the function call, to return to the model.
     */
    content?: string | null;
    /**
     * The name of the function to call.
     */
    name: string;
};

export type ChatCompletionRequestMessage = (ChatCompletionRequestDeveloperMessage & {
    role: 'developer';
}) | (ChatCompletionRequestSystemMessage & {
    role: 'system';
}) | (ChatCompletionRequestUserMessage & {
    role: 'user';
}) | (ChatCompletionRequestAssistantMessage & {
    role: 'assistant';
}) | (ChatCompletionRequestToolMessage & {
    role: 'tool';
}) | (ChatCompletionRequestFunctionMessage & {
    role: 'function';
});

/**
 * Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).
 */
export type ChatCompletionRequestMessageContentPartAudio = {
    input_audio: InputAudio;
};

export type ChatCompletionRequestMessageContentPartFile = {
    file: FileObject;
};

export type ChatCompletionRequestMessageContentPartImage = {
    image_url: ImageUrl;
};

export type ChatCompletionRequestMessageContentPartRefusal = {
    /**
     * The refusal message generated by the model.
     */
    refusal: string;
};

export type ChatCompletionRequestMessageContentPartText = {
    text: string;
};

export type ChatCompletionRequestSystemMessage = {
    /**
     * The contents of the system message.
     */
    content: ChatCompletionRequestSystemMessageContent;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
};

export type ChatCompletionRequestSystemMessageContent = string | Array<ChatCompletionRequestSystemMessageContentPart>;

export type ChatCompletionRequestSystemMessageContentPart = ChatCompletionRequestMessageContentPartText & {
    type: 'text';
};

/**
 * Tool message
 */
export type ChatCompletionRequestToolMessage = {
    /**
     * The contents of the tool message.
     */
    content: ChatCompletionRequestToolMessageContent;
    tool_call_id: string;
};

export type ChatCompletionRequestToolMessageContent = string | Array<ChatCompletionRequestToolMessageContentPart>;

export type ChatCompletionRequestToolMessageContentPart = ChatCompletionRequestMessageContentPartText & {
    type: 'text';
};

export type ChatCompletionRequestUserMessage = {
    /**
     * The contents of the user message.
     */
    content: ChatCompletionRequestUserMessageContent;
    /**
     * An optional name for the participant. Provides the model information to differentiate between participants of the same role.
     */
    name?: string | null;
};

export type ChatCompletionRequestUserMessageContent = string | Array<ChatCompletionRequestUserMessageContentPart>;

export type ChatCompletionRequestUserMessageContentPart = (ChatCompletionRequestMessageContentPartText & {
    type: 'text';
}) | (ChatCompletionRequestMessageContentPartImage & {
    type: 'image_url';
}) | (ChatCompletionRequestMessageContentPartAudio & {
    type: 'input_audio';
}) | (ChatCompletionRequestMessageContentPartFile & {
    type: 'file';
});

/**
 * A chat completion message generated by the model.
 */
export type ChatCompletionResponseMessage = {
    /**
     * The contents of the message.
     */
    content?: string | null;
    /**
     * The refusal message generated by the model.
     */
    refusal?: string | null;
    /**
     * The tool calls generated by the model, such as function calls.
     */
    tool_calls?: Array<ChatCompletionMessageToolCalls> | null;
    annotations?: Array<ChatCompletionResponseMessageAnnotation> | null;
    /**
     * The role of the author of this message.
     */
    role: Role;
    function_call?: null | FunctionCall;
    audio?: null | ChatCompletionResponseMessageAudio;
    /**
     * The contents of the reasoning message.
     */
    reasoning_content?: string | null;
};

export type ChatCompletionResponseMessageAnnotation = {
    url_citation: UrlCitation;
    type: 'url_citation';
};

export type ChatCompletionResponseMessageAudio = {
    /**
     * Unique identifier for this audio response.
     */
    id: string;
    /**
     * The Unix timestamp (in seconds) for when this audio response will no longer be accessible on the server for use in multi-turn conversations.
     */
    expires_at: number;
    /**
     * Base64 encoded audio bytes generated by the model, in the format specified in the request.
     */
    data: string;
    /**
     * Transcript of the audio generated by the model.
     */
    transcript: string;
};

/**
 * Options for streaming response. Only set this when you set `stream: true`.
 */
export type ChatCompletionStreamOptions = {
    /**
     * If set, an additional chunk will be streamed before the `data: [DONE]`
     * message. The `usage` field on this chunk shows the token usage statistics
     * for the entire request, and the `choices` field will always be an empty
     * array.
     *
     * All other chunks will also include a `usage` field, but with a null
     * value. **NOTE:** If the stream is interrupted, you may not receive the
     * final usage chunk which contains the total token usage for the request.
     */
    include_usage?: boolean | null;
    /**
     * When true, stream obfuscation will be enabled. Stream obfuscation adds
     * random characters to an `obfuscation` field on streaming delta events to
     * normalize payload sizes as a mitigation to certain side-channel attacks.
     * These obfuscation fields are included by default, but add a small amount
     * of overhead to the data stream. You can set `include_obfuscation` to
     * false to optimize for bandwidth if you trust the network links between
     * your application and the OpenAI API.
     */
    include_obfuscation?: boolean | null;
};

/**
 * A chat completion delta generated by streamed model responses.
 */
export type ChatCompletionStreamResponseDelta = {
    /**
     * The contents of the chunk message.
     */
    content?: string | null;
    function_call?: null | FunctionCallStream;
    tool_calls?: Array<ChatCompletionMessageToolCallChunk> | null;
    role?: null | Role;
    /**
     * The refusal message generated by the model.
     */
    refusal?: string | null;
    /**
     * The contents of the chunk reasoning message.
     */
    reasoning_content?: string | null;
};

export type ChatCompletionTokenLogprob = {
    /**
     * The token.
     */
    token: string;
    /**
     * The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
     */
    logprob: number;
    /**
     * A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
     */
    bytes?: Array<number> | null;
    /**
     * List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
     */
    top_logprobs: Array<TopLogprobs>;
};

export type ChatCompletionTool = {
    function: FunctionObject;
};

/**
 * Controls which (if any) tool is called by the model.
 * `none` means the model will not call any tool and instead generates a message.
 * `auto` means the model can pick between generating a message or calling one or more tools.
 * `required` means the model must call one or more tools.
 * Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
 *
 * `none` is the default when no tools are present. `auto` is the default if tools are present.
 */
export type ChatCompletionToolChoiceOption = (ChatCompletionAllowedToolsChoice & {
    type: 'allowed_tools';
}) | (ChatCompletionNamedToolChoice & {
    type: 'function';
}) | (ChatCompletionNamedToolChoiceCustom & {
    type: 'custom';
}) | (ToolChoiceOptions & {
    type: 'mode';
});

export type ChatCompletionTools = (ChatCompletionTool & {
    type: 'function';
}) | (CustomToolChatCompletions & {
    type: 'custom';
});

export type ChatRequest = {
    model: string;
    messages: Array<Message>;
    stream?: boolean | null;
    format?: string | null;
    keep_alive?: null | Duration;
    options?: null | Options;
};

/**
 * Breakdown of tokens used in a completion.
 */
export type CompletionTokensDetails = {
    accepted_prediction_tokens?: number | null;
    /**
     * Audio input tokens generated by the model.
     */
    audio_tokens?: number | null;
    /**
     * Tokens generated by the model for reasoning.
     */
    reasoning_tokens?: number | null;
    /**
     *  When using Predicted Outputs, the number of tokens in the
     * prediction that did not appear in the completion. However, like
     * reasoning tokens, these tokens are still counted in the total
     * completion tokens for purposes of billing, output, and context
     * window limits.
     */
    rejected_prediction_tokens?: number | null;
};

/**
 * Usage statistics for the completion request.
 */
export type CompletionUsage = {
    /**
     * Number of tokens in the prompt.
     */
    prompt_tokens: number;
    /**
     * Number of tokens in the generated completion.
     */
    completion_tokens: number;
    /**
     * Total number of tokens used in the request (prompt + completion).
     */
    total_tokens: number;
    prompt_tokens_details?: null | PromptTokensDetails;
    completion_tokens_details?: null | CompletionTokensDetails;
};

export type ContextLimits = {
    max_input_tokens?: number | null;
    max_output_tokens?: number | null;
};

export type CreateAliasRequest = {
    alias: string;
    repo: string;
    filename: string;
    snapshot?: string | null;
    request_params?: null | OaiRequestParams;
    context_params?: Array<string> | null;
};

/**
 * Request to create a new API model configuration
 */
export type CreateApiModelRequest = {
    /**
     * API format/protocol (e.g., "openai")
     */
    api_format: ApiFormat;
    /**
     * API base URL
     */
    base_url: string;
    /**
     * API key for authentication (null for public APIs)
     */
    api_key?: ApiKey;
    /**
     * List of available models
     */
    models: Array<string>;
    /**
     * Optional prefix for model namespacing (e.g., "azure/" for "azure/gpt-4", "openai:" for "openai:gpt-4")
     */
    prefix?: string | null;
    /**
     * Whether to forward all requests with this prefix (true) or only selected models (false)
     */
    forward_all_with_prefix?: boolean;
};

/**
 * Request to create a new API token
 */
export type CreateApiTokenRequest = {
    /**
     * Descriptive name for the API token (minimum 3 characters)
     */
    name?: string | null;
    /**
     * Token scope defining access level
     */
    scope: TokenScope;
};

export type CreateChatCompletionRequest = {
    /**
     * A list of messages comprising the conversation so far. Depending on the
     * [model](https://platform.openai.com/docs/models) you use, different message types (modalities)
     * are supported, like [text](https://platform.openai.com/docs/guides/text-generation),
     * [images](https://platform.openai.com/docs/guides/vision), and
     * [audio](https://platform.openai.com/docs/guides/audio).
     */
    messages: Array<ChatCompletionRequestMessage>;
    /**
     * Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI
     * offers a wide range of models with different capabilities, performance
     * characteristics, and price points. Refer to the
     * [model guide](https://platform.openai.com/docs/models)
     * to browse and compare available models.
     */
    model: string;
    /**
     * Output types that you would like the model to generate. Most models are capable of generating
     * text, which is the default:
     *
     * `["text"]`
     * The `gpt-4o-audio-preview` model can also be used to
     * [generate audio](https://platform.openai.com/docs/guides/audio). To request that this model
     * generate both text and audio responses, you can use:
     *
     * `["text", "audio"]`
     */
    modalities?: Array<ResponseModalities> | null;
    verbosity?: null | Verbosity;
    reasoning_effort?: null | ReasoningEffort;
    /**
     * An upper bound for the number of tokens that can be generated for a completion, including
     * visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).
     */
    max_completion_tokens?: number | null;
    /**
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on
     * their existing frequency in the text so far, decreasing the model's
     * likelihood to repeat the same line verbatim.
     */
    frequency_penalty?: number | null;
    /**
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on
     * whether they appear in the text so far, increasing the model's likelihood
     * to talk about new topics.
     */
    presence_penalty?: number | null;
    web_search_options?: null | WebSearchOptions;
    /**
     * An integer between 0 and 20 specifying the number of most likely tokens to
     * return at each token position, each with an associated log probability.
     * `logprobs` must be set to `true` if this parameter is used.
     */
    top_logprobs?: number | null;
    response_format?: null | ResponseFormat;
    audio?: null | ChatCompletionAudio;
    /**
     * Whether or not to store the output of this chat completion request for
     * use in our [model distillation](https://platform.openai.com/docs/guides/distillation) or
     * [evals](https://platform.openai.com/docs/guides/evals) products.
     *
     * Supports text and image inputs. Note: image inputs over 8MB will be dropped.
     */
    store?: boolean | null;
    /**
     * If set to true, the model response data will be streamed to the client
     * as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
     * See the [Streaming section below](https://platform.openai.com/docs/api-reference/chat/streaming)
     * for more information, along with the [streaming responses](https://platform.openai.com/docs/guides/streaming-responses)
     * guide for more information on how to handle the streaming events.
     */
    stream?: boolean | null;
    stop?: null | StopConfiguration;
    /**
     * Modify the likelihood of specified tokens appearing in the completion.
     *
     * Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100.
     * Mathematically, the bias is added to the logits generated by the model prior to sampling.
     * The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection;
     * values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
     */
    logit_bias?: {
        [key: string]: number;
    } | null;
    /**
     * Whether to return log probabilities of the output tokens or not. If true,
     * returns the log probabilities of each output token returned in the `content` of `message`.
     */
    logprobs?: boolean | null;
    /**
     * The maximum number of [tokens](https://platform.openai.com/tokenizer) that can be generated in
     * the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.
     * This value is now deprecated in favor of `max_completion_tokens`, and is
     * not compatible with [o-series models](https://platform.openai.com/docs/guides/reasoning).
     * @deprecated
     */
    max_tokens?: number | null;
    /**
     * How many chat completion choices to generate for each input message. Note that you will be
     * charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to
     * minimize costs.
     */
    n?: number | null;
    prediction?: null | PredictionContent;
    /**
     * This feature is in Beta.
     *
     * If specified, our system will make a best effort to sample deterministically, such that
     * repeated requests with the same `seed` and parameters should return the same result.
     *
     * Determinism is not guaranteed, and you should refer to the `system_fingerprint` response
     * parameter to monitor changes in the backend.
     * @deprecated
     */
    seed?: number | null;
    stream_options?: null | ChatCompletionStreamOptions;
    service_tier?: null | ServiceTier;
    /**
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random,
     * while lower values like 0.2 will make it more focused and deterministic.
     *
     * We generally recommend altering this or `top_p` but not both.
     */
    temperature?: number | null;
    /**
     * An alternative to sampling with temperature, called nucleus sampling,
     * where the model considers the results of the tokens with top_p probability mass.
     * So 0.1 means only the tokens comprising the top 10% probability mass are considered.
     *
     * We generally recommend altering this or `temperature` but not both.
     */
    top_p?: number | null;
    /**
     * A list of tools the model may call. You can provide either
     * [custom tools](https://platform.openai.com/docs/guides/function-calling#custom-tools) or
     * [function tools](https://platform.openai.com/docs/guides/function-calling).
     */
    tools?: Array<ChatCompletionTools> | null;
    tool_choice?: null | ChatCompletionToolChoiceOption;
    /**
     * Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)
     * during tool use.
     */
    parallel_tool_calls?: boolean | null;
    /**
     * This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key`
     * instead to maintain caching optimizations.
     * A stable identifier for your end-users.
     * Used to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and
     * prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
     * @deprecated
     */
    user?: string | null;
    /**
     * A stable identifier used to help detect users of your application that may be violating OpenAI's
     * usage policies.
     *
     * The IDs should be a string that uniquely identifies each user. We recommend hashing their username
     * or email address, in order to avoid sending us any identifying information. [Learn
     * more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).
     */
    safety_identifier?: string | null;
    /**
     * Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces
     * the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).
     */
    prompt_cache_key?: string | null;
    function_call?: null | ChatCompletionFunctionCall;
    /**
     * Deprecated in favor of `tools`.
     *
     * A list of functions the model may generate JSON inputs for.
     * @deprecated
     */
    functions?: Array<ChatCompletionFunctions> | null;
    metadata?: null | Metadata;
    /**
     * llama.cpp compatible extra params in request
     */
    chat_template_kwargs?: {} | null;
};

/**
 * Represents a chat completion response returned by model, based on the provided input.
 */
export type CreateChatCompletionResponse = {
    /**
     * A unique identifier for the chat completion.
     */
    id: string;
    /**
     * A list of chat completion choices. Can be more than one if `n` is greater than 1.
     */
    choices: Array<ChatChoice>;
    /**
     * The Unix timestamp (in seconds) of when the chat completion was created.
     */
    created: number;
    /**
     * The model used for the chat completion.
     */
    model: string;
    service_tier?: null | ServiceTier;
    /**
     * This fingerprint represents the backend configuration that the model runs with.
     *
     * Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
     * @deprecated
     */
    system_fingerprint?: string | null;
    /**
     * The object type, which is always `chat.completion`.
     */
    object: string;
    usage?: null | CompletionUsage;
};

/**
 * Represents a streamed chunk of a chat completion response returned by the model, based on the provided input. [Learn more](https://platform.openai.com/docs/guides/streaming-responses).
 */
export type CreateChatCompletionStreamResponse = {
    /**
     * A unique identifier for the chat completion. Each chunk has the same ID.
     */
    id: string;
    /**
     * A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the last chunk if you set `stream_options: {"include_usage": true}`.
     */
    choices: Array<ChatChoiceStream>;
    /**
     * The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
     */
    created: number;
    /**
     * The model to generate the completion.
     */
    model: string;
    service_tier?: null | ServiceTier;
    /**
     * This fingerprint represents the backend configuration that the model runs with.
     * Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
     * @deprecated
     */
    system_fingerprint?: string | null;
    /**
     * The object type, which is always `chat.completion.chunk`.
     */
    object: string;
    usage?: null | CompletionUsage;
};

export type CreateEmbeddingRequest = {
    /**
     * ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list)
     * API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models)
     * for descriptions of them.
     */
    model: string;
    /**
     * Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single
     * request, pass an array of strings or array of token arrays. The input must not exceed the max
     * input tokens for the model (8192 tokens for all embedding models), cannot be an empty string, and
     * any array must be 2048 dimensions or less. [Example Python
     * code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
     * In addition to the per-input token limit, all embedding  models enforce a maximum of 300,000
     * tokens summed across all inputs in a  single request.
     */
    input: EmbeddingInput;
    encoding_format?: null | EncodingFormat;
    /**
     * A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
     * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
     */
    user?: string | null;
    /**
     * The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
     */
    dimensions?: number | null;
};

export type CreateEmbeddingResponse = {
    object: string;
    /**
     * The name of the model used to generate the embedding.
     */
    model: string;
    /**
     * The list of embeddings generated by the model.
     */
    data: Array<Embedding>;
    /**
     * The usage information for the request.
     */
    usage: EmbeddingUsage;
};

/**
 * Request to create a toolset
 */
export type CreateToolsetRequest = {
    /**
     * Toolset type identifier (e.g., "builtin-exa-web-search")
     */
    toolset_type: string;
    /**
     * User-defined name for this toolset (2-24 chars, alphanumeric + spaces/dash/underscore)
     */
    name: string;
    /**
     * Optional description for this toolset
     */
    description?: string | null;
    /**
     * Whether this toolset is enabled
     */
    enabled?: boolean;
    /**
     * API key for the toolset
     */
    api_key: string;
};

export type CustomGrammarFormatParam = {
    /**
     * The grammar definition.
     */
    definition: string;
    /**
     * The syntax of the grammar definition. One of `lark` or `regex`.
     */
    syntax: GrammarSyntax;
};

export type CustomName = {
    /**
     * The name of the custom tool to call.
     */
    name: string;
};

export type CustomTool = {
    /**
     * The name of the custom tool to call.
     */
    name: string;
    /**
     * The input for the custom tool call generated by the model.
     */
    input: string;
};

export type CustomToolChatCompletions = {
    custom: CustomToolProperties;
};

export type CustomToolProperties = {
    /**
     * The name of the custom tool, used to identify it in tool calls.
     */
    name: string;
    /**
     * Optional description of the custom tool, used to provide more context.
     */
    description?: string | null;
    /**
     * The input format for the custom tool. Default is unconstrained text.
     */
    format: CustomToolPropertiesFormat;
};

export type CustomToolPropertiesFormat = {
    type: 'text';
} | {
    grammar: CustomGrammarFormatParam;
    type: 'grammar';
};

export type DownloadRequest = {
    id: string;
    repo: string;
    filename: string;
    status: DownloadStatus;
    error?: string | null;
    created_at: string;
    updated_at: string;
    total_bytes?: number | null;
    downloaded_bytes?: number;
    started_at: string;
};

export type DownloadStatus = 'pending' | 'completed' | 'error';

export type Duration = string;

/**
 * Represents an embedding vector returned by embedding endpoint.
 */
export type Embedding = {
    /**
     * The index of the embedding in the list of embeddings.
     */
    index: number;
    /**
     * The object type, which is always "embedding".
     */
    object: string;
    /**
     * The embedding vector, which is a list of floats. The length of vector
     * depends on the model as listed in the [embedding guide](https://platform.openai.com/docs/guides/embeddings).
     */
    embedding: Array<number>;
};

export type EmbeddingInput = string | Array<string> | Array<number> | Array<Array<number>>;

export type EmbeddingUsage = {
    /**
     * The number of tokens used by the prompt.
     */
    prompt_tokens: number;
    /**
     * The total number of tokens used by the request.
     */
    total_tokens: number;
};

export type EncodingFormat = 'float' | 'base64';

export type ErrorBody = {
    /**
     * Human-readable error message describing what went wrong
     */
    message: string;
    /**
     * Error type categorizing the kind of error that occurred
     */
    type: string;
    /**
     * Specific error code for programmatic error handling
     */
    code?: string | null;
    /**
     * Parameter name that caused the error (for validation errors)
     */
    param?: string | null;
};

/**
 * Request to execute a toolset
 */
export type ExecuteToolsetRequest = {
    /**
     * Function parameters as JSON
     */
    params: unknown;
};

/**
 * Request to fetch available models from provider
 */
export type FetchModelsRequest = {
    /**
     * Credentials to use for fetching models
     */
    creds?: TestCreds;
    /**
     * API base URL (required - always needed to know where to fetch models from)
     */
    base_url: string;
};

/**
 * Response containing available models from provider
 */
export type FetchModelsResponse = {
    models: Array<string>;
};

export type FileObject = {
    /**
     * The base64 encoded file data, used when passing the file to the model
     * as a string.
     */
    file_data?: string | null;
    /**
     * The ID of an uploaded file to use as input.
     */
    file_id?: string | null;
    /**
     * The name of the file, used when passing the file to the model as a
     * string.
     */
    filename?: string | null;
};

export type FinishReason = 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';

/**
 * The name and arguments of a function that should be called, as generated by the model.
 */
export type FunctionCall = {
    /**
     * The name of the function to call.
     */
    name: string;
    /**
     * The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
     */
    arguments: string;
};

export type FunctionCallStream = {
    /**
     * The name of the function to call.
     */
    name?: string | null;
    /**
     * The arguments to call the function with, as generated by the model in JSON format.
     * Note that the model does not always generate valid JSON, and may hallucinate
     * parameters not defined by your function schema. Validate the arguments in your
     * code before calling your function.
     */
    arguments?: string | null;
};

/**
 * Function definition within a tool
 */
export type FunctionDefinition = {
    /**
     * Simple tool name (e.g., "search", "findSimilar"). Frontend composes fully qualified name.
     */
    name: string;
    /**
     * Human-readable description for LLM
     */
    description: string;
    /**
     * JSON Schema for function parameters
     */
    parameters: unknown;
};

export type FunctionName = {
    /**
     * The name of the function to call.
     */
    name: string;
};

export type FunctionObject = {
    /**
     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: string;
    /**
     * A description of what the function does, used by the model to choose when and how to call the function.
     */
    description?: string | null;
    /**
     * The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.
     *
     * Omitting `parameters` defines a function with an empty parameter list.
     */
    parameters?: unknown;
    /**
     * Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).
     */
    strict?: boolean | null;
};

export type FunctionType = 'function';

export type GrammarSyntax = 'lark' | 'regex';

export type ImageDetail = 'auto' | 'low' | 'high';

export type ImageUrl = {
    /**
     * Either a URL of the image or the base64 encoded image data.
     */
    url: string;
    detail?: null | ImageDetail;
};

export type InputAudio = {
    /**
     * Base64 encoded audio data.
     */
    data: string;
    /**
     * The format of the encoded audio data. Currently supports "wav" and "mp3".
     */
    format: InputAudioFormat;
};

export type InputAudioFormat = 'wav' | 'mp3';

export type ListModelResponse = {
    object: string;
    data: Array<Model>;
};

/**
 * List of toolset types
 */
export type ListToolsetTypesResponse = {
    types: Array<ToolsetTypeResponse>;
};

/**
 * List of toolsets
 */
export type ListToolsetsResponse = {
    toolsets: Array<ToolsetResponse>;
};

/**
 * List users query parameters
 */
export type ListUsersParams = {
    page?: number | null;
    page_size?: number | null;
};

export type LocalModelResponse = {
    repo: string;
    filename: string;
    snapshot: string;
    size?: number | null;
    model_params: {};
    metadata?: null | ModelMetadata;
};

export type Message = {
    role: string;
    content: string;
    images?: Array<string> | null;
};

/**
 * Set of 16 key-value pairs that can be attached to an object.
 * This can be useful for storing additional information about the
 * object in a structured format, and querying for objects via API
 * or the dashboard. Keys are strings with a maximum length of 64
 * characters. Values are strings with a maximum length of 512
 * characters.
 */
export type Metadata = unknown;

/**
 * Describes an OpenAI model offering that can be used with the API.
 */
export type Model = {
    /**
     * The model identifier, which can be referenced in the API endpoints.
     */
    id: string;
    /**
     * The object type, which is always "model".
     */
    object: string;
    /**
     * The Unix timestamp (in seconds) when the model was created.
     */
    created: number;
    /**
     * The organization that owns the model.
     */
    owned_by: string;
};

export type ModelAlias = {
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
};

/**
 * Response for auto-discovered model aliases
 */
export type ModelAliasResponse = {
    source: string;
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
    metadata?: null | ModelMetadata;
};

export type ModelArchitecture = {
    family?: string | null;
    parameter_count?: number | null;
    quantization?: string | null;
    format: string;
};

export type ModelCapabilities = {
    vision?: boolean | null;
    audio?: boolean | null;
    thinking?: boolean | null;
    tools: ToolCapabilities;
};

export type ModelDetails = {
    parent_model?: string | null;
    format: string;
    family: string;
    families?: Array<string> | null;
    parameter_size: string;
    quantization_level: string;
};

/**
 * Model metadata for API responses
 */
export type ModelMetadata = {
    capabilities: ModelCapabilities;
    context: ContextLimits;
    architecture: ModelArchitecture;
    chat_template?: string | null;
};

export type ModelsResponse = {
    models: Array<OllamaModel>;
};

/**
 * Request to pull a model file from HuggingFace
 */
export type NewDownloadRequest = {
    /**
     * HuggingFace repository name in format 'username/repository-name'
     */
    repo: string;
    /**
     * Model file name to download (typically .gguf format)
     */
    filename: string;
};

export type OaiRequestParams = {
    frequency_penalty?: number | null;
    max_tokens?: number | null;
    presence_penalty?: number | null;
    seed?: number | null;
    stop?: Array<string>;
    temperature?: number | null;
    top_p?: number | null;
    user?: string | null;
};

export type OllamaError = {
    error: string;
};

export type OllamaModel = {
    model: string;
    modified_at: number;
    size: number;
    digest: string;
    details: ModelDetails;
};

export type OpenAiApiError = {
    /**
     * Error details following OpenAI API error format
     */
    error: ErrorBody;
};

export type Options = {
    num_keep?: number | null;
    seed?: number | null;
    num_predict?: number | null;
    top_k?: number | null;
    top_p?: number | null;
    tfs_z?: number | null;
    typical_p?: number | null;
    repeat_last_n?: number | null;
    temperature?: number | null;
    repeat_penalty?: number | null;
    presence_penalty?: number | null;
    frequency_penalty?: number | null;
    mirostat?: number | null;
    mirostat_tau?: number | null;
    mirostat_eta?: number | null;
    penalize_newline?: boolean | null;
    stop?: Array<string> | null;
    numa?: boolean | null;
    num_ctx?: number | null;
    num_batch?: number | null;
    num_gpu?: number | null;
    main_gpu?: number | null;
    low_vram?: boolean | null;
    f16_kv?: boolean | null;
    logits_all?: boolean | null;
    vocab_only?: boolean | null;
    use_mmap?: boolean | null;
    use_mlock?: boolean | null;
    num_thread?: number | null;
};

export type PaginatedAliasResponse = {
    data: Array<AliasResponse>;
    total: number;
    page: number;
    page_size: number;
};

/**
 * Paginated response for API model listings
 */
export type PaginatedApiModelResponse = {
    data: Array<ApiModelResponse>;
    total: number;
    page: number;
    page_size: number;
};

export type PaginatedApiTokenResponse = {
    data: Array<ApiToken>;
    total: number;
    page: number;
    page_size: number;
};

export type PaginatedDownloadResponse = {
    data: Array<DownloadRequest>;
    total: number;
    page: number;
    page_size: number;
};

export type PaginatedLocalModelResponse = {
    data: Array<LocalModelResponse>;
    total: number;
    page: number;
    page_size: number;
};

/**
 * Paginated response for access requests
 */
export type PaginatedUserAccessResponse = {
    /**
     * List of access requests
     */
    requests: Array<UserAccessRequest>;
    /**
     * Total number of requests
     */
    total: number;
    /**
     * Current page number
     */
    page: number;
    /**
     * Number of items per page
     */
    page_size: number;
};

export type PaginatedUserAliasResponse = {
    data: Array<UserAliasResponse>;
    total: number;
    page: number;
    page_size: number;
};

/**
 * Query parameters for pagination and sorting
 */
export type PaginationSortParams = {
    /**
     * Page number (1-based indexing)
     */
    page?: number;
    /**
     * Number of items to return per page (maximum 100)
     */
    page_size?: number;
    /**
     * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
     */
    sort?: string | null;
    /**
     * Sort order: 'asc' for ascending, 'desc' for descending
     */
    sort_order?: string;
};

/**
 * Response to the ping endpoint
 */
export type PingResponse = {
    /**
     * Simple ping response message
     */
    message: string;
};

/**
 * The type of the predicted content you want to provide. This type is
 * currently always `content`.
 */
export type PredictionContent = {
    /**
     * The type of the predicted content you want to provide. This type is
     * currently always `content`.
     */
    content: PredictionContentContent;
    type: 'content';
};

/**
 * The content that should be matched when generating a model response. If generated tokens would match this content, the entire model response can be returned much more quickly.
 */
export type PredictionContentContent = string | Array<ChatCompletionRequestMessageContentPartText>;

/**
 * Breakdown of tokens used in a completion.
 */
export type PromptTokensDetails = {
    /**
     * Audio input tokens present in the prompt.
     */
    audio_tokens?: number | null;
    /**
     * Cached tokens present in the prompt.
     */
    cached_tokens?: number | null;
};

/**
 * Response for queue status operations
 */
export type QueueStatusResponse = {
    /**
     * Queue status ("idle" or "processing")
     */
    status: string;
};

export type ReasoningEffort = 'none' | 'minimal' | 'low' | 'medium' | 'high' | 'xhigh';

export type RedirectResponse = {
    /**
     * The URL to redirect to (OAuth authorization URL or application home page)
     */
    location: string;
};

/**
 * Refresh request - discriminated union by source field
 */
export type RefreshRequest = {
    source: 'all';
} | {
    /**
     * Repository in format "user/repo"
     */
    repo: string;
    /**
     * Filename of the GGUF model
     */
    filename: string;
    /**
     * Snapshot/commit identifier
     */
    snapshot: string;
    source: 'model';
};

/**
 * Response for metadata refresh operations
 */
export type RefreshResponse = {
    /**
     * Number of models queued ("all" for bulk refresh, "1" for single)
     */
    num_queued: string;
    /**
     * Model alias (only for single model refresh)
     */
    alias?: string | null;
};

/**
 * Source type discriminator for refresh requests
 */
export type RefreshSource = 'all' | 'model';

export type ResourceRole = 'resource_user' | 'resource_power_user' | 'resource_manager' | 'resource_admin';

export type ResponseFormat = {
    type: 'text';
} | {
    type: 'json_object';
} | {
    json_schema: ResponseFormatJsonSchema;
    type: 'json_schema';
};

export type ResponseFormatJsonSchema = {
    /**
     * A description of what the response format is for, used by the model to determine how to respond in the format.
     */
    description?: string | null;
    /**
     * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: string;
    /**
     * The schema for the response format, described as a JSON Schema object.
     * Learn how to build JSON schemas [here](https://json-schema.org/).
     */
    schema?: unknown;
    /**
     * Whether to enable strict schema adherence when generating the output.
     * If set to true, the model will always follow the exact schema defined
     * in the `schema` field. Only a subset of JSON Schema is supported when
     * `strict` is `true`. To learn more, read the [Structured Outputs
     * guide](https://platform.openai.com/docs/guides/structured-outputs).
     */
    strict?: boolean | null;
};

/**
 * Output types that you would like the model to generate for this request.
 *
 * Most models are capable of generating text, which is the default: `["text"]`
 *
 * The `gpt-4o-audio-preview` model can also be used to [generate
 * audio](https://platform.openai.com/docs/guides/audio). To request that this model generate both text and audio responses, you can use: `["text", "audio"]`
 */
export type ResponseModalities = 'text' | 'audio';

export type Role = 'system' | 'user' | 'assistant' | 'tool' | 'function';

export type ServiceTier = 'auto' | 'default' | 'flex' | 'scale' | 'priority';

export type SettingInfo = {
    key: string;
    current_value: unknown;
    default_value: unknown;
    source: SettingSource;
    metadata: SettingMetadata;
};

export type SettingMetadata = {
    type: 'string';
} | {
    min: number;
    max: number;
    type: 'number';
} | {
    type: 'boolean';
} | {
    options: Array<string>;
    type: 'option';
};

export type SettingSource = 'system' | 'command_line' | 'environment' | 'settings_file' | 'default';

/**
 * Request to setup the application in authenticated mode
 */
export type SetupRequest = {
    /**
     * Server name for identification (minimum 10 characters)
     */
    name: string;
    /**
     * Optional description of the server's purpose
     */
    description?: string | null;
};

/**
 * Response containing the updated application status after setup
 */
export type SetupResponse = {
    /**
     * New application status after successful setup
     */
    status: AppStatus;
};

export type ShowRequest = {
    name: string;
};

export type ShowResponse = {
    details: ModelDetails;
    license: string;
    model_info: {};
    modelfile: string;
    modified_at: number;
    parameters: string;
    template: string;
};

export type StopConfiguration = string | Array<string>;

/**
 * Credentials for test/fetch operations
 */
export type TestCreds = {
    /**
     * Look up credentials from stored API model
     */
    value: string;
    type: 'id';
} | {
    /**
     * Use direct API key (null for no authentication)
     */
    value: ApiKey;
    type: 'api_key';
};

/**
 * Request to test API connectivity with a prompt
 */
export type TestPromptRequest = {
    /**
     * Credentials to use for testing
     */
    creds?: TestCreds;
    /**
     * API base URL
     */
    base_url: string;
    /**
     * Model to use for testing
     */
    model: string;
    /**
     * Test prompt (max 30 characters for cost control)
     */
    prompt: string;
};

/**
 * Response from testing API connectivity
 */
export type TestPromptResponse = {
    success: boolean;
    response?: string | null;
    error?: string | null;
};

/**
 * API Token information response
 */
export type TokenInfo = {
    role: TokenScope;
};

export type TokenScope = 'scope_token_user' | 'scope_token_power_user' | 'scope_token_manager' | 'scope_token_admin';

export type TokenStatus = 'active' | 'inactive';

export type ToolCapabilities = {
    function_calling?: boolean | null;
    structured_output?: boolean | null;
};

export type ToolChoiceAllowedMode = 'auto' | 'required';

export type ToolChoiceOptions = 'none' | 'auto' | 'required';

/**
 * Tool definition in OpenAI format for LLM function calling.
 * Tool name follows Claude MCP convention: toolset__{toolset_id}__{tool_name}
 */
export type ToolDefinition = {
    /**
     * Type of tool (always "function" for now)
     */
    type: string;
    /**
     * Function definition details
     */
    function: FunctionDefinition;
};

/**
 * User-owned toolset instance with UUID identification
 */
export type Toolset = {
    /**
     * Unique instance identifier (UUID)
     */
    id: string;
    /**
     * User-defined name for this instance
     */
    name: string;
    /**
     * Toolset type identifier (e.g., "builtin-exa-web-search")
     */
    toolset_type: string;
    /**
     * Optional description for this instance
     */
    description?: string | null;
    /**
     * Whether this instance is enabled
     */
    enabled: boolean;
    /**
     * Whether this instance has an API key configured
     */
    has_api_key: boolean;
    /**
     * When this instance was created
     */
    created_at: string;
    /**
     * When this instance was last updated
     */
    updated_at: string;
};

/**
 * Response from toolset tool execution (to send back to LLM)
 */
export type ToolsetExecutionResponse = {
    /**
     * Successful result (JSON), if any
     */
    result?: unknown;
    /**
     * Error message, if execution failed
     */
    error?: string | null;
};

/**
 * Toolset response
 */
export type ToolsetResponse = {
    /**
     * Unique instance identifier (UUID)
     */
    id: string;
    /**
     * User-defined name for this toolset
     */
    name: string;
    /**
     * Toolset type identifier (e.g., "builtin-exa-web-search")
     */
    toolset_type: string;
    /**
     * Optional description for this toolset
     */
    description?: string | null;
    /**
     * Whether this toolset is enabled
     */
    enabled: boolean;
    /**
     * Whether this toolset has an API key configured
     */
    has_api_key: boolean;
    /**
     * Whether the toolset type is enabled at app level
     */
    app_enabled: boolean;
    /**
     * Tools provided by this toolset type
     */
    tools: Array<ToolDefinition>;
    /**
     * When this toolset was created
     */
    created_at: string;
    /**
     * When this toolset was last updated
     */
    updated_at: string;
};

/**
 * Toolset type response (for admin listing)
 */
export type ToolsetTypeResponse = {
    /**
     * Unique toolset type identifier (e.g., "builtin-exa-web-search")
     */
    toolset_id: string;
    /**
     * Human-readable name (e.g., "Exa Web Search")
     */
    name: string;
    /**
     * Description of the toolset
     */
    description: string;
    /**
     * Whether the toolset is enabled at app level (admin-controlled)
     */
    app_enabled: boolean;
    /**
     * Tools provided by this toolset
     */
    tools: Array<ToolDefinition>;
};

/**
 * Toolset with app-level configuration status (API response model)
 */
export type ToolsetWithTools = {
    /**
     * Unique toolset identifier (e.g., "builtin-exa-web-search")
     */
    toolset_id: string;
    /**
     * Human-readable name (e.g., "Exa Web Search")
     */
    name: string;
    /**
     * Description of the toolset
     */
    description: string;
    /**
     * Whether the toolset is enabled at app level (admin-controlled)
     */
    app_enabled: boolean;
    /**
     * Tools provided by this toolset
     */
    tools: Array<ToolDefinition>;
};

export type TopLogprobs = {
    /**
     * The token.
     */
    token: string;
    /**
     * The log probability of this token.
     */
    logprob: number;
    /**
     * A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
     */
    bytes?: Array<number> | null;
};

export type UpdateAliasRequest = {
    repo: string;
    filename: string;
    snapshot?: string | null;
    request_params?: null | OaiRequestParams;
    context_params?: Array<string> | null;
};

/**
 * Request to update an existing API model configuration
 */
export type UpdateApiModelRequest = {
    /**
     * API format/protocol (required)
     */
    api_format: ApiFormat;
    /**
     * API base URL (required)
     */
    base_url: string;
    /**
     * API key update action (Keep/Set with Some or None)
     */
    api_key?: ApiKeyUpdateAction;
    /**
     * List of available models (required)
     */
    models: Array<string>;
    /**
     * Optional prefix for model namespacing
     */
    prefix?: string | null;
    /**
     * Whether to forward all requests with this prefix (true) or only selected models (false)
     */
    forward_all_with_prefix?: boolean;
};

/**
 * Request to update an existing API token
 */
export type UpdateApiTokenRequest = {
    /**
     * New descriptive name for the token (minimum 3 characters)
     */
    name: string;
    /**
     * New status for the token (active/inactive)
     */
    status: TokenStatus;
};

/**
 * Request to update a setting value
 */
export type UpdateSettingRequest = {
    /**
     * New value for the setting (type depends on setting metadata)
     */
    value: unknown;
};

/**
 * Request to update a toolset (full PUT - all fields required except api_key)
 */
export type UpdateToolsetRequest = {
    /**
     * User-defined name for this toolset
     */
    name: string;
    /**
     * Optional description for this toolset
     */
    description?: string | null;
    /**
     * Whether this toolset is enabled
     */
    enabled: boolean;
    /**
     * API key update action (Keep or Set)
     */
    api_key?: ApiKeyUpdateDto;
};

export type UrlCitation = {
    /**
     * The index of the last character of the URL citation in the message.
     */
    end_index: number;
    /**
     * The index of the first character of the URL citation in the message.
     */
    start_index: number;
    /**
     * The title of the web resource.
     */
    title: string;
    /**
     * The URL of the web resource.
     */
    url: string;
};

export type UserAccessRequest = {
    /**
     * Unique identifier for the request
     */
    id: number;
    /**
     * Username of the requesting user
     */
    username: string;
    /**
     * User ID (UUID) of the requesting user
     */
    user_id: string;
    reviewer?: string | null;
    /**
     * Current status of the request
     */
    status: UserAccessRequestStatus;
    /**
     * Creation timestamp
     */
    created_at: string;
    /**
     * Last update timestamp
     */
    updated_at: string;
};

export type UserAccessRequestStatus = 'pending' | 'approved' | 'rejected';

/**
 * Response for checking access request status
 */
export type UserAccessStatusResponse = {
    /**
     * Username of the requesting user
     */
    username: string;
    /**
     * Current status of the request (pending, approved, rejected)
     */
    status: UserAccessRequestStatus;
    /**
     * Creation timestamp
     */
    created_at: string;
    /**
     * Last update timestamp
     */
    updated_at: string;
};

export type UserAlias = {
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
    request_params?: OaiRequestParams;
    context_params?: Array<string>;
};

export type UserAliasResponse = {
    alias: string;
    repo: string;
    filename: string;
    snapshot: string;
    source: string;
    model_params: {};
    request_params: OaiRequestParams;
    context_params: Array<string>;
    metadata?: null | ModelMetadata;
};

export type UserInfo = {
    user_id: string;
    username: string;
    first_name?: string | null;
    last_name?: string | null;
    role?: null | AppRole;
};

export type UserListResponse = {
    client_id: string;
    users: Array<UserInfo>;
    page: number;
    page_size: number;
    total_pages: number;
    total_users: number;
    has_next: boolean;
    has_previous: boolean;
};

/**
 * User authentication response with discriminated union
 */
export type UserResponse = {
    auth_status: 'logged_out';
} | (UserInfo & {
    auth_status: 'logged_in';
}) | (TokenInfo & {
    auth_status: 'api_token';
});

export type UserScope = 'scope_user_user' | 'scope_user_power_user' | 'scope_user_manager' | 'scope_user_admin';

/**
 * Constrains the verbosity of the model's response. Lower values will result in more concise responses, while higher values will result in more verbose responses. Currently supported values are `low`, `medium`, and `high`.
 */
export type Verbosity = 'low' | 'medium' | 'high';

/**
 * The amount of context window space to use for the search.
 */
export type WebSearchContextSize = 'low' | 'medium' | 'high';

/**
 * Approximate location parameters for the search.
 */
export type WebSearchLocation = {
    /**
     * The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.
     */
    country?: string | null;
    /**
     * Free text input for the region of the user, e.g. `California`.
     */
    region?: string | null;
    /**
     * Free text input for the city of the user, e.g. `San Francisco`.
     */
    city?: string | null;
    /**
     * The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.
     */
    timezone?: string | null;
};

/**
 * Options for the web search tool.
 */
export type WebSearchOptions = {
    search_context_size?: null | WebSearchContextSize;
    user_location?: null | WebSearchUserLocation;
};

export type WebSearchUserLocation = {
    type: WebSearchUserLocationType;
    approximate: WebSearchLocation;
};

export type WebSearchUserLocationType = 'approximate';

export type ChatOllamaModelData = {
    /**
     * Chat request in Ollama format
     */
    body: ChatRequest;
    path?: never;
    query?: never;
    url: '/api/chat';
};

export type ChatOllamaModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model not found
     */
    404: OllamaError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ChatOllamaModelError = ChatOllamaModelErrors[keyof ChatOllamaModelErrors];

export type ChatOllamaModelResponses = {
    /**
     * Chat response
     */
    200: unknown;
};

export type ShowOllamaModelData = {
    /**
     * Model name to get details for
     */
    body: ShowRequest;
    path?: never;
    query?: never;
    url: '/api/show';
};

export type ShowOllamaModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model not found
     */
    404: OllamaError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ShowOllamaModelError = ShowOllamaModelErrors[keyof ShowOllamaModelErrors];

export type ShowOllamaModelResponses = {
    /**
     * Model details
     */
    200: ShowResponse;
};

export type ShowOllamaModelResponse = ShowOllamaModelResponses[keyof ShowOllamaModelResponses];

export type ListOllamaModelsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/api/tags';
};

export type ListOllamaModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListOllamaModelsError = ListOllamaModelsErrors[keyof ListOllamaModelsErrors];

export type ListOllamaModelsResponses = {
    /**
     * List of available models
     */
    200: ModelsResponse;
};

export type ListOllamaModelsResponse = ListOllamaModelsResponses[keyof ListOllamaModelsResponses];

export type ListAllAccessRequestsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/access-requests';
};

export type ListAllAccessRequestsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListAllAccessRequestsError = ListAllAccessRequestsErrors[keyof ListAllAccessRequestsErrors];

export type ListAllAccessRequestsResponses = {
    /**
     * All requests retrieved
     */
    200: PaginatedUserAccessResponse;
};

export type ListAllAccessRequestsResponse = ListAllAccessRequestsResponses[keyof ListAllAccessRequestsResponses];

export type ListPendingAccessRequestsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/access-requests/pending';
};

export type ListPendingAccessRequestsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListPendingAccessRequestsError = ListPendingAccessRequestsErrors[keyof ListPendingAccessRequestsErrors];

export type ListPendingAccessRequestsResponses = {
    /**
     * Pending requests retrieved
     */
    200: PaginatedUserAccessResponse;
};

export type ListPendingAccessRequestsResponse = ListPendingAccessRequestsResponses[keyof ListPendingAccessRequestsResponses];

export type ApproveAccessRequestData = {
    /**
     * Role to assign to the user
     */
    body: ApproveUserAccessRequest;
    path: {
        /**
         * Access request ID
         */
        id: number;
    };
    query?: never;
    url: '/bodhi/v1/access-requests/{id}/approve';
};

export type ApproveAccessRequestErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ApproveAccessRequestError = ApproveAccessRequestErrors[keyof ApproveAccessRequestErrors];

export type ApproveAccessRequestResponses = {
    /**
     * Request approved successfully
     */
    200: unknown;
};

export type RejectAccessRequestData = {
    body?: never;
    path: {
        /**
         * Access request ID
         */
        id: number;
    };
    query?: never;
    url: '/bodhi/v1/access-requests/{id}/reject';
};

export type RejectAccessRequestErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RejectAccessRequestError = RejectAccessRequestErrors[keyof RejectAccessRequestErrors];

export type RejectAccessRequestResponses = {
    /**
     * Request rejected successfully
     */
    200: unknown;
};

export type ListApiModelsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/api-models';
};

export type ListApiModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListApiModelsError = ListApiModelsErrors[keyof ListApiModelsErrors];

export type ListApiModelsResponses = {
    /**
     * API model configurations retrieved successfully
     */
    200: PaginatedApiModelResponse;
};

export type ListApiModelsResponse = ListApiModelsResponses[keyof ListApiModelsResponses];

export type CreateApiModelData = {
    body: CreateApiModelRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models';
};

export type CreateApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Alias already exists
     */
    409: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateApiModelError = CreateApiModelErrors[keyof CreateApiModelErrors];

export type CreateApiModelResponses = {
    /**
     * API model created
     */
    201: ApiModelResponse;
};

export type CreateApiModelResponse = CreateApiModelResponses[keyof CreateApiModelResponses];

export type GetApiFormatsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models/api-formats';
};

export type GetApiFormatsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetApiFormatsError = GetApiFormatsErrors[keyof GetApiFormatsErrors];

export type GetApiFormatsResponses = {
    /**
     * API formats retrieved successfully
     */
    200: ApiFormatsResponse;
};

export type GetApiFormatsResponse = GetApiFormatsResponses[keyof GetApiFormatsResponses];

export type FetchApiModelsData = {
    body: FetchModelsRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models/fetch-models';
};

export type FetchApiModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type FetchApiModelsError = FetchApiModelsErrors[keyof FetchApiModelsErrors];

export type FetchApiModelsResponses = {
    /**
     * Available models
     */
    200: FetchModelsResponse;
};

export type FetchApiModelsResponse = FetchApiModelsResponses[keyof FetchApiModelsResponses];

export type TestApiModelData = {
    body: TestPromptRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/api-models/test';
};

export type TestApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type TestApiModelError = TestApiModelErrors[keyof TestApiModelErrors];

export type TestApiModelResponses = {
    /**
     * Test result
     */
    200: TestPromptResponse;
};

export type TestApiModelResponse = TestApiModelResponses[keyof TestApiModelResponses];

export type DeleteApiModelData = {
    body?: never;
    path: {
        /**
         * API model ID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}';
};

export type DeleteApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type DeleteApiModelError = DeleteApiModelErrors[keyof DeleteApiModelErrors];

export type DeleteApiModelResponses = {
    /**
     * API model deleted
     */
    204: void;
};

export type DeleteApiModelResponse = DeleteApiModelResponses[keyof DeleteApiModelResponses];

export type GetApiModelData = {
    body?: never;
    path: {
        /**
         * Unique identifier for the API model alias
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}';
};

export type GetApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model with specified ID not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetApiModelError = GetApiModelErrors[keyof GetApiModelErrors];

export type GetApiModelResponses = {
    /**
     * API model configuration retrieved successfully
     */
    200: ApiModelResponse;
};

export type GetApiModelResponse = GetApiModelResponses[keyof GetApiModelResponses];

export type UpdateApiModelData = {
    body: UpdateApiModelRequest;
    path: {
        /**
         * API model ID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}';
};

export type UpdateApiModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateApiModelError = UpdateApiModelErrors[keyof UpdateApiModelErrors];

export type UpdateApiModelResponses = {
    /**
     * API model updated
     */
    200: ApiModelResponse;
};

export type UpdateApiModelResponse = UpdateApiModelResponses[keyof UpdateApiModelResponses];

export type SyncModelsData = {
    body?: never;
    path: {
        /**
         * Unique identifier for the API model alias
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/api-models/{id}/sync-models';
};

export type SyncModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * API model not found
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type SyncModelsError = SyncModelsErrors[keyof SyncModelsErrors];

export type SyncModelsResponses = {
    /**
     * Models synced to cache successfully
     */
    200: ApiModelResponse;
};

export type SyncModelsResponse = SyncModelsResponses[keyof SyncModelsResponses];

export type RequestAccessData = {
    /**
     * Application client requesting access
     */
    body: AppAccessRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/apps/request-access';
};

export type RequestAccessErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RequestAccessError = RequestAccessErrors[keyof RequestAccessErrors];

export type RequestAccessResponses = {
    /**
     * Access granted successfully
     */
    200: AppAccessResponse;
};

export type RequestAccessResponse = RequestAccessResponses[keyof RequestAccessResponses];

export type CompleteOAuthFlowData = {
    /**
     * OAuth callback parameters from authorization server
     */
    body: AuthCallbackRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/auth/callback';
};

export type CompleteOAuthFlowErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * OAuth error, invalid request parameters, or state mismatch
     */
    422: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CompleteOAuthFlowError = CompleteOAuthFlowErrors[keyof CompleteOAuthFlowErrors];

export type CompleteOAuthFlowResponses = {
    /**
     * OAuth flow completed successfully, user authenticated
     */
    200: RedirectResponse;
};

export type CompleteOAuthFlowResponse = CompleteOAuthFlowResponses[keyof CompleteOAuthFlowResponses];

export type InitiateOAuthFlowData = {
    body: unknown;
    path?: never;
    query?: never;
    url: '/bodhi/v1/auth/initiate';
};

export type InitiateOAuthFlowErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type InitiateOAuthFlowError = InitiateOAuthFlowErrors[keyof InitiateOAuthFlowErrors];

export type InitiateOAuthFlowResponses = {
    /**
     * User already authenticated, home page URL provided
     */
    200: RedirectResponse;
    /**
     * User not authenticated, OAuth authorization URL provided
     */
    201: RedirectResponse;
};

export type InitiateOAuthFlowResponse = InitiateOAuthFlowResponses[keyof InitiateOAuthFlowResponses];

export type GetAppInfoData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/info';
};

export type GetAppInfoErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetAppInfoError = GetAppInfoErrors[keyof GetAppInfoErrors];

export type GetAppInfoResponses = {
    /**
     * Application information retrieved successfully
     */
    200: AppInfo;
};

export type GetAppInfoResponse = GetAppInfoResponses[keyof GetAppInfoResponses];

export type LogoutUserData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/logout';
};

export type LogoutUserErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type LogoutUserError = LogoutUserErrors[keyof LogoutUserErrors];

export type LogoutUserResponses = {
    /**
     * User logged out successfully
     */
    200: RedirectResponse;
};

export type LogoutUserResponse = LogoutUserResponses[keyof LogoutUserResponses];

export type ListModelFilesData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/modelfiles';
};

export type ListModelFilesErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListModelFilesError = ListModelFilesErrors[keyof ListModelFilesErrors];

export type ListModelFilesResponses = {
    /**
     * Local model files retrieved successfully from cache
     */
    200: PaginatedLocalModelResponse;
};

export type ListModelFilesResponse = ListModelFilesResponses[keyof ListModelFilesResponses];

export type ListDownloadsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/modelfiles/pull';
};

export type ListDownloadsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListDownloadsError = ListDownloadsErrors[keyof ListDownloadsErrors];

export type ListDownloadsResponses = {
    /**
     * Model download requests retrieved successfully
     */
    200: PaginatedDownloadResponse;
};

export type ListDownloadsResponse = ListDownloadsResponses[keyof ListDownloadsResponses];

export type PullModelFileData = {
    /**
     * Model file download specification with repository and filename
     */
    body: NewDownloadRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/modelfiles/pull';
};

export type PullModelFileErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type PullModelFileError = PullModelFileErrors[keyof PullModelFileErrors];

export type PullModelFileResponses = {
    /**
     * Existing download request found
     */
    200: DownloadRequest;
    /**
     * Download request created
     */
    201: DownloadRequest;
};

export type PullModelFileResponse = PullModelFileResponses[keyof PullModelFileResponses];

export type PullModelByAliasData = {
    body?: never;
    path: {
        /**
         * Predefined model alias. Available aliases include popular models like llama2:chat, mistral:instruct, phi3:mini, etc. Use the /models endpoint to see all available aliases.
         */
        alias: string;
    };
    query?: never;
    url: '/bodhi/v1/modelfiles/pull/{alias}';
};

export type PullModelByAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Alias not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type PullModelByAliasError = PullModelByAliasErrors[keyof PullModelByAliasErrors];

export type PullModelByAliasResponses = {
    /**
     * Existing download request found
     */
    200: DownloadRequest;
    /**
     * Download request created
     */
    201: DownloadRequest;
};

export type PullModelByAliasResponse = PullModelByAliasResponses[keyof PullModelByAliasResponses];

export type GetDownloadStatusData = {
    body?: never;
    path: {
        /**
         * Unique identifier of the download request (UUID format)
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/modelfiles/pull/{id}';
};

export type GetDownloadStatusErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Download request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetDownloadStatusError = GetDownloadStatusErrors[keyof GetDownloadStatusErrors];

export type GetDownloadStatusResponses = {
    /**
     * Download request found
     */
    200: DownloadRequest;
};

export type GetDownloadStatusResponse = GetDownloadStatusResponses[keyof GetDownloadStatusResponses];

export type ListAllModelsData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/models';
};

export type ListAllModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListAllModelsError = ListAllModelsErrors[keyof ListAllModelsErrors];

export type ListAllModelsResponses = {
    /**
     * Paginated list of model aliases retrieved successfully
     */
    200: PaginatedAliasResponse;
};

export type ListAllModelsResponse = ListAllModelsResponses[keyof ListAllModelsResponses];

export type CreateAliasData = {
    body: CreateAliasRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/models';
};

export type CreateAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateAliasError = CreateAliasErrors[keyof CreateAliasErrors];

export type CreateAliasResponses = {
    /**
     * Alias created succesfully
     */
    201: UserAliasResponse;
};

export type CreateAliasResponse = CreateAliasResponses[keyof CreateAliasResponses];

export type RefreshModelMetadataData = {
    /**
     * Refresh request - either bulk (source='all') or single model (source='model' with identifiers)
     */
    body: RefreshRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/models/refresh';
};

export type RefreshModelMetadataErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model alias not found for specified repo/filename/snapshot
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RefreshModelMetadataError = RefreshModelMetadataErrors[keyof RefreshModelMetadataErrors];

export type RefreshModelMetadataResponses = {
    /**
     * Metadata refreshed successfully (sync mode)
     */
    200: ModelAliasResponse;
    /**
     * Metadata refresh queued in background (bulk mode)
     */
    202: RefreshResponse;
};

export type RefreshModelMetadataResponse = RefreshModelMetadataResponses[keyof RefreshModelMetadataResponses];

export type GetAliasData = {
    body?: never;
    path: {
        /**
         * Alias identifier for the model
         */
        alias: string;
    };
    query?: never;
    url: '/bodhi/v1/models/{alias}';
};

export type GetAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Alias not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetAliasError = GetAliasErrors[keyof GetAliasErrors];

export type GetAliasResponses = {
    /**
     * Model alias details
     */
    200: UserAliasResponse;
};

export type GetAliasResponse = GetAliasResponses[keyof GetAliasResponses];

export type UpdateAliasData = {
    body: UpdateAliasRequest;
    path: {
        /**
         * Alias identifier
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/models/{id}';
};

export type UpdateAliasErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateAliasError = UpdateAliasErrors[keyof UpdateAliasErrors];

export type UpdateAliasResponses = {
    /**
     * Alias updated succesfully
     */
    200: UserAliasResponse;
};

export type UpdateAliasResponse = UpdateAliasResponses[keyof UpdateAliasResponses];

export type GetQueueStatusData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/queue';
};

export type GetQueueStatusErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetQueueStatusError = GetQueueStatusErrors[keyof GetQueueStatusErrors];

export type GetQueueStatusResponses = {
    /**
     * Queue status retrieved successfully
     */
    200: QueueStatusResponse;
};

export type GetQueueStatusResponse = GetQueueStatusResponses[keyof GetQueueStatusResponses];

export type ListSettingsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/settings';
};

export type ListSettingsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListSettingsError = ListSettingsErrors[keyof ListSettingsErrors];

export type ListSettingsResponses = {
    /**
     * Application settings retrieved successfully
     */
    200: Array<SettingInfo>;
};

export type ListSettingsResponse = ListSettingsResponses[keyof ListSettingsResponses];

export type DeleteSettingData = {
    body?: never;
    path: {
        /**
         * Setting key identifier to reset to default value
         */
        key: string;
    };
    query?: never;
    url: '/bodhi/v1/settings/{key}';
};

export type DeleteSettingErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Setting not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type DeleteSettingError = DeleteSettingErrors[keyof DeleteSettingErrors];

export type DeleteSettingResponses = {
    /**
     * Setting reset to default successfully
     */
    200: SettingInfo;
};

export type DeleteSettingResponse = DeleteSettingResponses[keyof DeleteSettingResponses];

export type UpdateSettingData = {
    /**
     * Request to update a setting value
     */
    body: {
        /**
         * New value for the setting (type depends on setting metadata)
         */
        value: unknown;
    };
    path: {
        /**
         * Setting key identifier (e.g., BODHI_LOG_LEVEL, BODHI_PORT)
         */
        key: string;
    };
    query?: never;
    url: '/bodhi/v1/settings/{key}';
};

export type UpdateSettingErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Setting not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateSettingError = UpdateSettingErrors[keyof UpdateSettingErrors];

export type UpdateSettingResponses = {
    /**
     * Setting updated successfully
     */
    200: SettingInfo;
};

export type UpdateSettingResponse = UpdateSettingResponses[keyof UpdateSettingResponses];

export type SetupAppData = {
    /**
     * Application setup configuration
     */
    body: SetupRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/setup';
};

export type SetupAppErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type SetupAppError = SetupAppErrors[keyof SetupAppErrors];

export type SetupAppResponses = {
    /**
     * Application setup completed successfully
     */
    200: SetupResponse;
};

export type SetupAppResponse = SetupAppResponses[keyof SetupAppResponses];

export type ListApiTokensData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based indexing)
         */
        page?: number;
        /**
         * Number of items to return per page (maximum 100)
         */
        page_size?: number;
        /**
         * Field to sort by. Common values: repo, filename, size, updated_at, snapshot, created_at
         */
        sort?: string;
        /**
         * Sort order: 'asc' for ascending, 'desc' for descending
         */
        sort_order?: string;
    };
    url: '/bodhi/v1/tokens';
};

export type ListApiTokensErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListApiTokensError = ListApiTokensErrors[keyof ListApiTokensErrors];

export type ListApiTokensResponses = {
    /**
     * List of API tokens
     */
    200: PaginatedApiTokenResponse;
};

export type ListApiTokensResponse = ListApiTokensResponses[keyof ListApiTokensResponses];

export type CreateApiTokenData = {
    /**
     * API token creation parameters
     */
    body: CreateApiTokenRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/tokens';
};

export type CreateApiTokenErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateApiTokenError = CreateApiTokenErrors[keyof CreateApiTokenErrors];

export type CreateApiTokenResponses = {
    /**
     * API token created successfully
     */
    201: ApiTokenResponse;
};

export type CreateApiTokenResponse = CreateApiTokenResponses[keyof CreateApiTokenResponses];

export type UpdateApiTokenData = {
    /**
     * Token update request
     */
    body: UpdateApiTokenRequest;
    path: {
        /**
         * Unique identifier of the API token to update
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/tokens/{id}';
};

export type UpdateApiTokenErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Token not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateApiTokenError = UpdateApiTokenErrors[keyof UpdateApiTokenErrors];

export type UpdateApiTokenResponses = {
    /**
     * Token updated successfully
     */
    200: ApiToken;
};

export type UpdateApiTokenResponse = UpdateApiTokenResponses[keyof UpdateApiTokenResponses];

export type ListToolsetTypesData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/toolset_types';
};

export type ListToolsetTypesErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListToolsetTypesError = ListToolsetTypesErrors[keyof ListToolsetTypesErrors];

export type ListToolsetTypesResponses = {
    /**
     * List of all toolset types
     */
    200: ListToolsetTypesResponse;
};

export type ListToolsetTypesResponse2 = ListToolsetTypesResponses[keyof ListToolsetTypesResponses];

export type DisableToolsetTypeData = {
    body?: never;
    path: {
        /**
         * Toolset type identifier
         */
        type_id: string;
    };
    query?: never;
    url: '/bodhi/v1/toolset_types/{type_id}/app-config';
};

export type DisableToolsetTypeErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Toolset type not found
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type DisableToolsetTypeError = DisableToolsetTypeErrors[keyof DisableToolsetTypeErrors];

export type DisableToolsetTypeResponses = {
    /**
     * Toolset type disabled
     */
    200: AppToolsetConfigResponse;
};

export type DisableToolsetTypeResponse = DisableToolsetTypeResponses[keyof DisableToolsetTypeResponses];

export type EnableToolsetTypeData = {
    body?: never;
    path: {
        /**
         * Toolset type identifier
         */
        type_id: string;
    };
    query?: never;
    url: '/bodhi/v1/toolset_types/{type_id}/app-config';
};

export type EnableToolsetTypeErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Toolset type not found
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type EnableToolsetTypeError = EnableToolsetTypeErrors[keyof EnableToolsetTypeErrors];

export type EnableToolsetTypeResponses = {
    /**
     * Toolset type enabled
     */
    200: AppToolsetConfigResponse;
};

export type EnableToolsetTypeResponse = EnableToolsetTypeResponses[keyof EnableToolsetTypeResponses];

export type ListToolsetsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/toolsets';
};

export type ListToolsetsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListToolsetsError = ListToolsetsErrors[keyof ListToolsetsErrors];

export type ListToolsetsResponses = {
    /**
     * List of user's toolsets
     */
    200: ListToolsetsResponse;
};

export type ListToolsetsResponse2 = ListToolsetsResponses[keyof ListToolsetsResponses];

export type CreateToolsetData = {
    body: CreateToolsetRequest;
    path?: never;
    query?: never;
    url: '/bodhi/v1/toolsets';
};

export type CreateToolsetErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Name already exists
     */
    409: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateToolsetError = CreateToolsetErrors[keyof CreateToolsetErrors];

export type CreateToolsetResponses = {
    /**
     * Toolset created
     */
    201: ToolsetResponse;
};

export type CreateToolsetResponse = CreateToolsetResponses[keyof CreateToolsetResponses];

export type DeleteToolsetData = {
    body?: never;
    path: {
        /**
         * Toolset instance UUID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/toolsets/{id}';
};

export type DeleteToolsetErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Toolset not found or not owned
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type DeleteToolsetError = DeleteToolsetErrors[keyof DeleteToolsetErrors];

export type DeleteToolsetResponses = {
    /**
     * Toolset deleted
     */
    204: void;
};

export type DeleteToolsetResponse = DeleteToolsetResponses[keyof DeleteToolsetResponses];

export type GetToolsetData = {
    body?: never;
    path: {
        /**
         * Toolset instance UUID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/toolsets/{id}';
};

export type GetToolsetErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Toolset not found or not owned
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetToolsetError = GetToolsetErrors[keyof GetToolsetErrors];

export type GetToolsetResponses = {
    /**
     * Toolset
     */
    200: ToolsetResponse;
};

export type GetToolsetResponse = GetToolsetResponses[keyof GetToolsetResponses];

export type UpdateToolsetData = {
    body: UpdateToolsetRequest;
    path: {
        /**
         * Toolset instance UUID
         */
        id: string;
    };
    query?: never;
    url: '/bodhi/v1/toolsets/{id}';
};

export type UpdateToolsetErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Toolset not found or not owned
     */
    404: unknown;
    /**
     * Name already exists
     */
    409: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type UpdateToolsetError = UpdateToolsetErrors[keyof UpdateToolsetErrors];

export type UpdateToolsetResponses = {
    /**
     * Toolset updated
     */
    200: ToolsetResponse;
};

export type UpdateToolsetResponse = UpdateToolsetResponses[keyof UpdateToolsetResponses];

export type ExecuteToolsetData = {
    body: ExecuteToolsetRequest;
    path: {
        /**
         * Toolset instance UUID
         */
        id: string;
        /**
         * Tool method name
         */
        method: string;
    };
    query?: never;
    url: '/bodhi/v1/toolsets/{id}/execute/{method}';
};

export type ExecuteToolsetErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Toolset or method not found
     */
    404: unknown;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ExecuteToolsetError = ExecuteToolsetErrors[keyof ExecuteToolsetErrors];

export type ExecuteToolsetResponses = {
    /**
     * Tool execution result
     */
    200: ToolsetExecutionResponse;
};

export type ExecuteToolsetResponse = ExecuteToolsetResponses[keyof ExecuteToolsetResponses];

export type GetCurrentUserData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/user';
};

export type GetCurrentUserErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetCurrentUserError = GetCurrentUserErrors[keyof GetCurrentUserErrors];

export type GetCurrentUserResponses = {
    /**
     * User information (authenticated or not)
     */
    200: UserResponse;
};

export type GetCurrentUserResponse = GetCurrentUserResponses[keyof GetCurrentUserResponses];

export type RequestUserAccessData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/user/request-access';
};

export type RequestUserAccessErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Pending request already exists
     */
    409: OpenAiApiError;
    /**
     * User already has role
     */
    422: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RequestUserAccessError = RequestUserAccessErrors[keyof RequestUserAccessErrors];

export type RequestUserAccessResponses = {
    /**
     * Access request created successfully
     */
    201: unknown;
};

export type GetUserAccessStatusData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/bodhi/v1/user/request-status';
};

export type GetUserAccessStatusErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Request not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetUserAccessStatusError = GetUserAccessStatusErrors[keyof GetUserAccessStatusErrors];

export type GetUserAccessStatusResponses = {
    /**
     * Request status retrieved
     */
    200: UserAccessStatusResponse;
};

export type GetUserAccessStatusResponse = GetUserAccessStatusResponses[keyof GetUserAccessStatusResponses];

export type ListUsersData = {
    body?: never;
    path?: never;
    query?: {
        /**
         * Page number (1-based)
         */
        page?: number;
        /**
         * Number of users per page
         */
        page_size?: number;
    };
    url: '/bodhi/v1/users';
};

export type ListUsersErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListUsersError = ListUsersErrors[keyof ListUsersErrors];

export type ListUsersResponses = {
    /**
     * Users retrieved successfully
     */
    200: UserListResponse;
};

export type ListUsersResponse = ListUsersResponses[keyof ListUsersResponses];

export type RemoveUserData = {
    body?: never;
    path: {
        /**
         * User ID to remove
         */
        user_id: string;
    };
    query?: never;
    url: '/bodhi/v1/users/{user_id}';
};

export type RemoveUserErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * User not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type RemoveUserError = RemoveUserErrors[keyof RemoveUserErrors];

export type RemoveUserResponses = {
    /**
     * User removed successfully
     */
    200: unknown;
};

export type ChangeUserRoleData = {
    body: ChangeRoleRequest;
    path: {
        /**
         * User ID to change role for
         */
        user_id: string;
    };
    query?: never;
    url: '/bodhi/v1/users/{user_id}/role';
};

export type ChangeUserRoleErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * User not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ChangeUserRoleError = ChangeUserRoleErrors[keyof ChangeUserRoleErrors];

export type ChangeUserRoleResponses = {
    /**
     * Role changed successfully
     */
    200: unknown;
};

export type HealthCheckData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/health';
};

export type HealthCheckErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type HealthCheckError = HealthCheckErrors[keyof HealthCheckErrors];

export type HealthCheckResponses = {
    /**
     * Application is healthy and fully operational
     */
    200: PingResponse;
};

export type HealthCheckResponse = HealthCheckResponses[keyof HealthCheckResponses];

export type PingServerData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/ping';
};

export type PingServerErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type PingServerError = PingServerErrors[keyof PingServerErrors];

export type PingServerResponses = {
    /**
     * Server is responding normally
     */
    200: PingResponse;
};

export type PingServerResponse = PingServerResponses[keyof PingServerResponses];

export type CreateChatCompletionData = {
    body: CreateChatCompletionRequest;
    path?: never;
    query?: never;
    url: '/v1/chat/completions';
};

export type CreateChatCompletionErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateChatCompletionError = CreateChatCompletionErrors[keyof CreateChatCompletionErrors];

export type CreateChatCompletionResponses = {
    /**
     * Chat completion response
     */
    200: CreateChatCompletionResponse;
    /**
     * Chat completion stream, the status is 200, using 201 to avoid OpenAPI format limitation.
     */
    201: CreateChatCompletionStreamResponse;
};

export type CreateChatCompletionResponse2 = CreateChatCompletionResponses[keyof CreateChatCompletionResponses];

export type CreateEmbeddingData = {
    body: CreateEmbeddingRequest;
    path?: never;
    query?: never;
    url: '/v1/embeddings';
};

export type CreateEmbeddingErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type CreateEmbeddingError = CreateEmbeddingErrors[keyof CreateEmbeddingErrors];

export type CreateEmbeddingResponses = {
    /**
     * Embedding response
     */
    200: CreateEmbeddingResponse;
};

export type CreateEmbeddingResponse2 = CreateEmbeddingResponses[keyof CreateEmbeddingResponses];

export type ListModelsData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/v1/models';
};

export type ListModelsErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type ListModelsError = ListModelsErrors[keyof ListModelsErrors];

export type ListModelsResponses = {
    /**
     * List of available models
     */
    200: ListModelResponse;
};

export type ListModelsResponse = ListModelsResponses[keyof ListModelsResponses];

export type GetModelData = {
    body?: never;
    path: {
        /**
         * Model identifier - can be user alias (e.g., 'llama2:chat'), model alias, or API provider alias
         */
        id: string;
    };
    query?: never;
    url: '/v1/models/{id}';
};

export type GetModelErrors = {
    /**
     * Invalid request parameters
     */
    400: OpenAiApiError;
    /**
     * Not authenticated
     */
    401: OpenAiApiError;
    /**
     * Insufficient permissions
     */
    403: OpenAiApiError;
    /**
     * Model not found
     */
    404: OpenAiApiError;
    /**
     * Internal server error
     */
    500: OpenAiApiError;
};

export type GetModelError = GetModelErrors[keyof GetModelErrors];

export type GetModelResponses = {
    /**
     * Model details
     */
    200: Model;
};

export type GetModelResponse = GetModelResponses[keyof GetModelResponses];

export type ClientOptions = {
    baseUrl: 'http://localhost:1135' | (string & {});
};