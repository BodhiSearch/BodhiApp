[package]
name = "bodhi"
version = "0.1.0"
edition = "2021"
description = "Run LLMs locally"
license = "MIT"
authors = ["Amir Nagri <amir.nagri@gmail.com>"]

[features]
# This feature is used for production builds or when a dev server is not specified, DO NOT REMOVE!!
custom-protocol = ["tauri/custom-protocol"]

[dependencies]
anyhow = "1.0.81"
async-openai = "0.20.0"
axum = "0.7.4"
chrono = { version = "0.4.38", features = ["serde"] }
clap = { version = "4.5.2", features = ["derive"] }
dirs = "5.0.1"
dotenv = "0.15.0"
futures-util = "0.3.30"
include_dir = "0.7.3"
llama-server-bindings = { version = "0.1.0", path = "../../llama-server-bindings" }
mime_guess = "2.0.4"
regex = "1.10.4"
serde = { version = "1.0.197", features = ["derive"] }
serde_json = "1.0.114"
tauri = { version = "1.6.1", features = [ "api-all", "system-tray"] }
thiserror = "1.0.59"
tokio = { version = "1.36.0", features = ["full"] }
tokio-stream = "0.1.15"
tower-http = { version = "0.5.2", features = ["trace", "cors"] }
tracing = { version = "0.1.40", features = ["async-await", "log"] }
tracing-subscriber = { version = "0.3.18", features = ["env-filter"] }

[dev-dependencies]
fs2 = "0.4.3"
lazy_static = "1.4.0"
mousse = "0.1.1"
rand = "0.8.5"
reqwest = "0.12.3"
rstest = "0.19.0"
tempdir = "0.3.7"
tempfile = "3.10.1"

[build-dependencies]
anyhow = "1.0.81"
fs_extra = "1.3.0"
tauri-build = { version = "1.5.1", features = [] }
