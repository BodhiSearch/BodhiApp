import { ModelInfo } from './types';

export const recommendedModels: ModelInfo[] = [
  {
    id: 'mistral-7b',
    name: 'Mistral-7B',
    repo: 'mistralai/Mistral-7B-v0.1',
    fileName: 'mistral-7b-q4_K_M.gguf',
    quantization: 'Q4_K_M',
    size: '4.1GB',
    parameters: '7B',
    leaderboardRank: 3,
    category: 'medium',
    ratings: { quality: 4.5, speed: 4, accuracy: 4.5 },
    license: 'Apache 2.0',
    downloadState: { status: 'idle' },
  },
  {
    id: 'phi2',
    name: 'Phi-2',
    repo: 'microsoft/phi-2',
    fileName: 'phi-2-q4_K_M.gguf',
    quantization: 'Q4_K_M',
    size: '2.1GB',
    parameters: '2.7B',
    leaderboardRank: 5,
    category: 'small',
    ratings: { quality: 4, speed: 5, accuracy: 4 },
    license: 'MIT',
    downloadState: {
      status: 'downloading',
      progress: 45,
      speed: '10.5 MB/s',
      timeRemaining: '5 minutes',
    },
  },
  {
    id: 'neural-7b',
    name: 'Neural-7B',
    repo: 'neural/neural-7b',
    fileName: 'neural-7b-q4_K_M.gguf',
    quantization: 'Q4_K_M',
    size: '3.9GB',
    parameters: '7B',
    leaderboardRank: 7,
    category: 'medium',
    ratings: { quality: 4, speed: 4, accuracy: 4 },
    license: 'Apache 2.0',
    downloadState: { status: 'complete' },
  },
];

export const additionalModels: Record<string, ModelInfo[]> = {
  'Small Models (1-3B)': [
    {
      id: 'phi-1.5',
      name: 'Phi-1.5',
      repo: 'microsoft/phi-1.5',
      fileName: 'phi-1.5-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '1.8GB',
      parameters: '1.3B',
      leaderboardRank: 12,
      category: 'small',
      ratings: { quality: 3.5, speed: 5, accuracy: 3.5 },
      license: 'MIT',
      downloadState: { status: 'idle' },
    },
    {
      id: 'tinyllama',
      name: 'TinyLlama',
      repo: 'TinyLlama/TinyLlama-1.1B',
      fileName: 'tinyllama-1.1b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '0.6GB',
      parameters: '1.1B',
      leaderboardRank: 15,
      category: 'small',
      ratings: { quality: 3, speed: 5, accuracy: 3 },
      license: 'Apache 2.0',
      downloadState: { status: 'idle' },
    },
  ],
  'Medium Models (4-7B)': [
    {
      id: 'openchat-3.5',
      name: 'OpenChat 3.5',
      repo: 'openchat/openchat-3.5',
      fileName: 'openchat-3.5-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '4.3GB',
      parameters: '7B',
      leaderboardRank: 4,
      category: 'medium',
      ratings: { quality: 4.5, speed: 4, accuracy: 4.5 },
      license: 'Apache 2.0',
      downloadState: { status: 'idle' },
    },
    {
      id: 'stable-beluga',
      name: 'StableBeluga 7B',
      repo: 'stabilityai/stable-beluga-7b',
      fileName: 'stable-beluga-7b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '4.1GB',
      parameters: '7B',
      leaderboardRank: 8,
      category: 'medium',
      ratings: { quality: 4, speed: 4, accuracy: 4 },
      license: 'Apache 2.0',
      downloadState: {
        status: 'downloading',
        progress: 23,
        speed: '8.2 MB/s',
        timeRemaining: '8 minutes',
      },
    },
  ],
  'Large Models (8-13B)': [
    {
      id: 'mixtral-8x7b',
      name: 'Mixtral 8x7B',
      repo: 'mistralai/Mixtral-8x7B',
      fileName: 'mixtral-8x7b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '26GB',
      parameters: '47B',
      leaderboardRank: 1,
      category: 'large',
      ratings: { quality: 5, speed: 3, accuracy: 5 },
      license: 'Apache 2.0',
      downloadState: { status: 'idle' },
    },
    {
      id: 'llama2-13b',
      name: 'Llama 2 13B',
      repo: 'meta-llama/Llama-2-13b',
      fileName: 'llama-2-13b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '7.5GB',
      parameters: '13B',
      leaderboardRank: 6,
      category: 'large',
      ratings: { quality: 4.5, speed: 3.5, accuracy: 4.5 },
      license: 'Meta License',
      downloadState: { status: 'complete' },
    },
  ],
};
