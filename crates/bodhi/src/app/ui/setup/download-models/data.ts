import { ModelInfo } from '@/app/ui/setup/download-models/types';

export const recommendedModels: ModelInfo[] = [
  {
    id: 'deepseek-r1-distill-llama-8b',
    name: 'DeepSeek-R1-Distill-Llama-8B',
    repo: 'bartowski/DeepSeek-R1-Distill-Llama-8B-GGUF',
    filename: 'DeepSeek-R1-Distill-Llama-8B-Q4_K_M.gguf',
    quantization: 'Q4_K_M',
    size: '4.92 GB',
    parameters: '8B',
    category: 'medium',
    ratings: { quality: 3, speed: 4, accuracy: 3 },
    license: 'MIT',
    downloadState: { status: 'idle' },
  },
  {
    id: 'meta-llama-3.1-8b-instruct',
    name: 'Meta-Llama-3.1-8B-Instruct',
    repo: 'bartowski/Meta-Llama-3.1-8B-Instruct-GGUF',
    filename: 'Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf',
    quantization: 'Q4_K_M',
    size: '4.92GB',
    parameters: '8B',
    category: 'medium',
    ratings: { quality: 3, speed: 4, accuracy: 3 },
    license: 'llama3.1',
    downloadState: {
      status: 'idle',
      progress: 45,
      speed: '10.5 MB/s',
      timeRemaining: '5 minutes',
    },
  },
  {
    id: 'phi-3.5-mini-128k-instruct',
    name: 'Phi-3.5-Mini-128k-Instruct',
    repo: 'bartowski/Phi-3.5-mini-instruct-GGUF',
    filename: 'Phi-3.5-mini-instruct-Q8_0.gguf',
    quantization: 'Q8_0',
    size: '4.1GB',
    parameters: '3.8B',
    category: 'small',
    ratings: { quality: 3, speed: 4, accuracy: 3 },
    license: 'MIT',
    downloadState: { status: 'idle' },
  },
];

export const additionalModels: Record<string, ModelInfo[]> = {
  'Small Models (1-3B)': [
    {
      id: 'phi-1.5',
      name: 'Phi-1.5',
      repo: 'microsoft/phi-1.5',
      filename: 'phi-1.5-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '1.8GB',
      parameters: '1.3B',
      category: 'small',
      ratings: { quality: 3.5, speed: 5, accuracy: 3.5 },
      license: 'MIT',
      downloadState: { status: 'idle' },
    },
    {
      id: 'tinyllama',
      name: 'TinyLlama',
      repo: 'TinyLlama/TinyLlama-1.1B',
      filename: 'tinyllama-1.1b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '0.6GB',
      parameters: '1.1B',
      category: 'small',
      ratings: { quality: 3, speed: 5, accuracy: 3 },
      license: 'Apache 2.0',
      downloadState: { status: 'idle' },
    },
  ],
  'Medium Models (4-7B)': [
    {
      id: 'openchat-3.5',
      name: 'OpenChat 3.5',
      repo: 'openchat/openchat-3.5',
      filename: 'openchat-3.5-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '4.3GB',
      parameters: '7B',
      category: 'medium',
      ratings: { quality: 4.5, speed: 4, accuracy: 4.5 },
      license: 'Apache 2.0',
      downloadState: { status: 'idle' },
    },
    {
      id: 'stable-beluga',
      name: 'StableBeluga 7B',
      repo: 'stabilityai/stable-beluga-7b',
      filename: 'stable-beluga-7b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '4.1GB',
      parameters: '7B',
      category: 'medium',
      ratings: { quality: 4, speed: 4, accuracy: 4 },
      license: 'Apache 2.0',
      downloadState: {
        status: 'pending',
        progress: 23,
        speed: '8.2 MB/s',
        timeRemaining: '8 minutes',
      },
    },
  ],
  'Large Models (8-13B)': [
    {
      id: 'mixtral-8x7b',
      name: 'Mixtral 8x7B',
      repo: 'mistralai/Mixtral-8x7B',
      filename: 'mixtral-8x7b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '26GB',
      parameters: '47B',
      category: 'large',
      ratings: { quality: 5, speed: 3, accuracy: 5 },
      license: 'Apache 2.0',
      downloadState: { status: 'idle' },
    },
    {
      id: 'llama2-13b',
      name: 'Llama 2 13B',
      repo: 'meta-llama/Llama-2-13b',
      filename: 'llama-2-13b-q4_K_M.gguf',
      quantization: 'Q4_K_M',
      size: '7.5GB',
      parameters: '13B',
      category: 'large',
      ratings: { quality: 4.5, speed: 3.5, accuracy: 4.5 },
      license: 'Meta License',
      downloadState: { status: 'completed' },
    },
  ],
};
