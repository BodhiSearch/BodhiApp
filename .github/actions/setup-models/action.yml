name: setup-models
description: Setup HuggingFace model caching and download required models
inputs:
  platform:
    description: "Platform to build for"
    required: true
  hf-home:
    description: "HuggingFace home directory path"
    required: true

runs:
  using: composite
  steps:
    - name: Cache HuggingFace models
      uses: actions/cache@v4
      id: cache-hf
      with:
        path: ${{ inputs.hf-home }}
        key: hf-cache-test-models-v0
        enableCrossOsArchive: true

    - name: Check and Download model
      if: steps.cache-hf.outputs.cache-hit != 'true'
      shell: bash
      env:
        HF_HOME: ${{ inputs.hf-home }}
      run: |
        hf download --revision daeb8e2d528a760970442092f6bf1e55c3b659eb ggml-org/Qwen3-1.7B-GGUF Qwen3-1.7B-Q8_0.gguf
        hf download --revision 4bcbc666d2f0d2b04d06f046d6baccdab79eac61 afrideva/Llama-68M-Chat-v1-GGUF llama-68m-chat-v1.q8_0.gguf